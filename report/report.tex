\documentclass[a4paper,english,titlepage,11pt]{report}

\usepackage{verimagstudent}
\usepackage{mathcomp,amssymb}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{mathenv}
\usepackage{tikz}
\usepackage{listings}
\usepackage{placeins}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage[toc,page]{appendix} 
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}

\newcommand*\system[1]{\left[ \begin{array}{lllll}#1 \end{array}\right.}


\def\R{\mathbb{R}}
\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
\def\Q{\mathbb{Q}}
\def\P{\mathcal{P}}
\def\ite{\textnormal{ite\ }}
\def\lfp{\textnormal{\it lfp}}
\newcommand{\widening}{\mathop{\triangledown}}

\definecolor{trefle}{rgb}{0,0.5,0}
\definecolor{moka}{rgb}{0.5,0.25,0}
\definecolor{minuit}{rgb}{0,0,0.5}

\tikzstyle{arrow}=[->,line width=.05cm,draw=red!90!blue!60!black]

\usetikzlibrary{snakes,arrows,shapes,backgrounds,shadows,automata,patterns}
%\usepgflibrary{snakes}

\tikzstyle{state}=[circle,fill=black!25,minimum size=13pt,inner sep=0pt]
\tikzstyle{rstate}=[rectangle,fill=black!25,minimum size=13pt,inner sep=0pt]
\tikzstyle{transition}=[rectangle,semithick,draw=black!75,
  			  minimum size=4mm]
\tikzstyle{transition2}=[transition,rectangle,thick,dashed,
  			  minimum size=4mm]
\tikzstyle{PRstate}=[circle,double,draw,fill=blue!15,minimum size=13pt,inner sep=0pt]
\tikzstyle{polyhedra}=[blue!25,opacity=0.5,pattern=north west lines,pattern
color=blue]
\tikzstyle{line}=[black,thick]

\lstnewenvironment{LLVM}
{\lstset{language=C,
		basicstyle=\ttfamily\footnotesize,
		commentstyle=\color{moka}\textit,
		keywordstyle=\color{minuit},
		identifierstyle=\color{trefle},
		showstringspaces=false}}
{}

\lstnewenvironment{C}
{\lstset{language=C,
		basicstyle=\ttfamily,
		commentstyle=\color{moka}\textit,
		keywordstyle=\color{minuit},
		identifierstyle=\color{trefle},
		showstringspaces=false}}
{}

\lstnewenvironment{Csmall}
{\lstset{language=C,
		basicstyle=\ttfamily\small,
		commentstyle=\color{moka}\textit,
		keywordstyle=\color{minuit},
		identifierstyle=\color{trefle},
		showstringspaces=false}}
{}
\title{Static Analysis by Path Focusing}
\author{Julien Henry}
\date{2011}
\shorttitle{Static Analysis by Path Focusing}
\institute{Grenoble-INP}
\abstract{
	Program verification is aimed at statically discovering properties on programs,
	such as the values that can take the different variables during execution.
	Abstract Interpretation is a technique that allows to compute an
	approximation of the set of these values, since it is impossible to compute
	the real set in general.
	This report takes place in the many attempts to improve the precision of
	static Analysis by Abstract Interpretation. It proposes a technique that
	takes benefit of SMT-solving to obtain more precise results at reasonable
	cost.
}
\resume{  
	La vérification de programme consiste à découvrir statiquement des
	propriétés sur des programmes, comme l'ensemble des valeurs que peuvent
	prendre les variables durant l'exécution. L'Interprétation Abstraite est une
	technique permettant de calculer une approximation de cet ensemble, le
	véritable ensemble étant impossible à calculer en général.
	Ce rapport s'inscrit dans la lignée des travaux visant à améliorer la
	précision de l'analyse par interprétation abstraite, et propose une
	technique tirant parti du SMT-solving pour obtenir de meilleurs résultats
	à un coût raisonnable.
}
\keywords{Static Program Analysis, Verification, Abstract Interpretation,
Invariant Generation, Path Focusing, SMT-Solving}
\motscles{Analyse Statique de Programmes, Vérification, Interprétation
Abstraite, Génération d'invariants, Découverte de Chemins, SMT-Solving}
\tutor{David Monniaux - Matthieu Moy}
%\notes{some notes}
\webaddress{Julien.Henry@imag.fr}
\reporttype{M2R Internship Report}

\acknowledgement{
	I would like to thank my two tutors, David Monniaux and Matthieu Moy, for
	their direction of my master thesis, and for their help everytime I needed
	it. I thank them for all their explanations that clearified lots of
	my questions, and for their advices for the redaction of this report.\\
	I also thank Laure Gonnord for inviting me to present my work at the GDR GPL
	2011.\\
	Finally, I thank all the Synchrone team and the Verimag laboratory for their
	cheerful welcome.
}

\begin{document}
  
  \maketitlepage

  \tableofcontents
  
  \newpage



\chapter{Introduction} 

Static analysis aims at automatically computing properties on programs, such as
the possible values of their variables during execution. This allows to show for
instance that a program will not overflow, will not divide by zero, and to compute
loop invariants\dots
The main applications of static analysis are compile-time optimisations, and
the proof of safety properties in critical systems, such as avionics.

Abstract Interpretation is a general framework used for static analysis.
Linear Relation Analysis (LRA) is a direct application of this framework, that
computes an upper-approximation of the set of the possible states of a numerical
program. The state of a program is defined by the position of the program
counter in the code, and the current values of the different numerical variables.
The set of possible states is expressed as a least fixpoint of a set of
equations defining the semantics of the program. 

A fundamental fact in static analysis is that it cannot be perfectly precise:
either the analysis is unsound (the set of possible states we compute does not contain all
the possible states during execution), or is incomplete (the computed set
contains states that can never be reached during execution). 
Abstract Interpretation is sound but incomplete, since it always computes an
upper-approximation of the set of possible states. The challenge is then to be
as precise as possible, so that we can prove properties about the program.

Linear Relation Analysis over-approximates the set of possible states as a
convex polyhedron where the dimensions are the numerical variables of the
program.
Instead of convex polyhedra, one could choose intervals, octagons, etc.
The fixpoint equation is computed iteratively; that is, successive
approximations of the set of reachable states are computed until they converge
to a fixpoint. 

Satisfiability Modulo Theory (SMT) solving is a technique
for deciding the satisfiability of a logic formula containing Boolean
predicates and elements of a theory, such as linear arithmetic relations between
integers.
In this report, we present a novel refinement of the Abstract Interpretation
technique, that uses SMT-solving to guide the fixpoint iterations, so that it
temporarily focuses on a selected path in the control flow graph (the graph
expressing the semantics of the program), in order to
obtain more precise results at reasonable cost.

\subsection*{Contribution and Organisation}

In this report we make the following contributions:
\begin{itemize}
\item We present a new technique, refered as \emph{Path Focusing}, that takes
benefits of the recent advances in the field of SMT-solving to improve precision
of static analysis by abstract interpretation. We also present an adaptation of
this technique to compute disjunctive invariants.
\item We present an implementation of this technique into a small analyser, as
well as the implementation of another technique proposed in \cite{GopanR06},
such that we can compare precision and cost of these two methods. This
implementation has been tested on a wide range of programs, including small
test-cases as well as real-life programs.
\end{itemize}

The report is organised as follows:
Part \ref{stateoftheartpart} introduces the state of the art in Abstract
Interpretation and more specifically in Linear Relation Analysis.
Part \ref{pathfocusingpart} describes the two techniques
\emph{Lookahead Widening} and \emph{Path Focusing}.
Part \ref{implementationpart} presents the implementation of these two
techniques into an analyser, and the experimental results we obtained.
Finally, Part \ref{future} introduces some directions to explore.

\chapter{Abstract Interpretation: state of the art}
\label{stateoftheartpart}

\section{Introductive example}

We consider the following program:

\begin{figure}[!h]
   \begin{minipage}[c]{.46\linewidth}
\begin{C}
x = 0;
while (x < 100) {
	x++;
}
\end{C}
   \end{minipage} \hfill
   \begin{minipage}[c]{.46\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.7cm,
                    semithick,font=\footnotesize]

	\node[state] (n0) {$p_0$};
	\node[state] (n1) [below of=n0] {$p_1$};
	\node[state] (n2) [below of=n1] {$p_2$};
	\node[state] (n3) [left of=n1] {$p_3$};

  \path [transition] 
		(n0) edge              node {$x \gets 0$} (n1);
  \path [transition] 
        (n1) edge			   node [above] {$x \geq 100$} (n3);
  \path [transition] 
        (n1) edge			   node [left] {$x < 100$} (n2);
  \path [transition] 
        (n2) edge [out=0, in=0, distance=2cm] node [right] {$x \gets x+1$} (n1);

\end{tikzpicture}
   \end{minipage}
\end{figure}
\FloatBarrier

Static analysis is aimed at discovering some properties about programs. In this
example, we would like to compute the set of possible values for the variable $x$ during execution.
The graph at the right side represents the program. The nodes of the graph are
called \emph{program points}. We can compute for instance the set $Y_1$ of
values for $x$ at point $p_1$. This set depends on the sets $Y_0$ and $Y_2$,
since there are two edges arriving at $p_1$: the first one comes from $p_0$, and
the second one from $p_2$.

There is a relation between $Y_1$ and $Y_2$ :
\begin{eqnarray*}
Y_1 &=& \{x\ |\ x=0 \vee \exists x' \in Y_2, x=x'+1 \} \\
Y_2 &=& \{x\ |\ x \in Y_1 \wedge x < 100 \}
\end{eqnarray*}
We see that $Y_1$ and $Y_2$ can be computed step by step:
we start with $Y_1 = Y_2 = \emptyset$.
Then, we add iteratively new elements in the sets.
\begin{itemize}
\item  We see that $0 \in Y_1$: $Y_1 = \{0\}$.
\item $Y_1$ contains $0$. So, $Y_2$ also contains $0$ by definition: $Y_2 =
\{0\}$.
\item $Y_2$ contains $0$, so $0+1=1$ is in $Y_1$: $Y_1 = \{0,1\}$.
\item Again, we find $Y_2 = \{0,1\}$.
\item $Y_2$ now contains $1$, so $1+1=2 \in Y_1$: $Y_1 = \{0,1,2\}$.
\item We continue the iteration until we find no more new elements in the
sets\dots
\end{itemize}

This computation is a fixpoint computation: the different sets are updated until
we find no more elements. These sets are strictly increasing (we always add new
elements in the sets), and if we find no new elements to add, that means we have
reached a limit. Abstract Interpretation gives a general framework to do such
kind of fixpoint computation.


\section{Abstract Interpretation}

Abstract Interpretation \cite{CC77,CousotCousot92-1} is a general method for
finding approximate solutions of
fixpoint equations. This method is used for program analysis, since analysing a
program often comes down to solving fixpoint equations, because of the loops and
recursive procedures.

However, most of the time, the solution of this fixpoint equation must be
computed in a complex domain: in program analysis, this could be the state space
of the program, i.e the set of all possible states of the program. This
computation quickly becomes too costly or does not terminate.

\subsection{Abstraction of the domain}

Abstract Interpretation proposes to represent more efficiently the
elements of this complex domain $C$ of concrete values,
by choosing a simpler domain  $A$ called \emph{abstract domain}. 
% DM: un peu lourd et peu clair

A concretization function $\gamma$ maps the elements of $A$ to elements of $C$:
\begin{eqnarray*}
\gamma: & A &\longrightarrow C \\
		& x &\longmapsto \gamma(x)
\end{eqnarray*}

The concrete semantics is a function $\Phi: C \rightarrow C$.
In the introductive example, this function $\Phi$ is the following:


$$\Phi\left[ \begin{array}{c}
Y_1 \\
Y_2 \\
Y_3 \\
Y_4
\end{array} \right] = \left[ \begin{array}{cc} 
x\ |& x \in \R \\
x\ |& x = 0 \vee \exists\  x'\in Y_2, x = x'+1 \\
x\ |& x \in Y_1 \wedge x < 100 \\
x\ |& x \in Y_1 \wedge x \geq 100 
\end{array} \right]$$


One can choose an abstract semantics $\Phi^\#: A \rightarrow A$ satisfying this
condition:

$$\forall x \in A, \Phi \circ \gamma (x) \subseteq_C \gamma \circ \Phi^\#(x)$$

$\Phi^\#$ is then an abstraction of $\Phi$, that gives an upper
approximation of $\gamma(x)$ when composed with $\gamma$. 



\begin{proposition}
Suppose $C$ is a complete lattice, and $\Phi$ is increasing from $C$ to $C$.
Each $x \in A$, satisfying the condition $\Phi^\#(x) \subseteq x$, is an abstraction of
the least fixpoint of $\Phi$.
\end{proposition}

Indeed, if $\Phi^\#(x) \subseteq x$, then $\Phi \circ \gamma (x) 
\subseteq \gamma \circ \Phi^\#(x) \subseteq \gamma(x)$.
Abstract interpretation aims at computing
such an~$x$. It computes the stationary limit of an ascending sequence
$(x_i)_{i \geq 0}$ defined by the induction:

$$\left[
\begin{array}{lll}
x_0 &=& \perp \\
x_{n+1} &=& x_n \sqcup \Phi^\#(x_n)
\end{array}
\right.
$$
where $\perp$ is the least element of $A$, and $\sqcup$ is an operator verifying
$x_1 \cup x_2 \subseteq x_1 \sqcup x_2$ and $x_1 \sqcup x_2 \in A$.
%The relation between these two
%domains is characterized by two functions, usually called 
%$\alpha\ :\ C \mapsto A$, $\gamma \ : \ A \mapsto C$, such as:
%
%$$\forall x \in C, \forall y \in A, \alpha(x) \leq_{A} y \Leftrightarrow x
%\leq_{C} \gamma(y) $$
%
%where $\leq_C$ and $\leq_A$ are the order relations on $C$ and $A$. Then, the
%fixpoint computation is done in the abstract domain, using the approximation of
%the function $\Phi$, i.e $\alpha(\Phi) = \alpha \circ \Phi \circ \gamma$, also
%noted $\Phi^\#$.
%We have the following result:
%
%\begin{proposition}
%If $C$ is a complete lattice, and if $\Phi$ is increasing from $C$ to $C$, then
%$$\alpha(\lfp(\Phi)) \leq_A \lfp(\alpha(\Phi))$$
%where $\lfp(\Phi)$ denotes the least fixpoint of $\Phi$.
%\end{proposition}
%
%In fact, one compute the least fixpoint of the function in the abstract
%domain, and the result of the computation also gives an upper approximation of
%the fixpoint in the concrete domain.


\subsection{Termination}

Termination of the fixpoint computation has to be guaranteed. This termination
depends on the properties of the abstract domain:
this one should be finite, of finite height,
or more generally satisfy the \emph{ascending chain condition},
meaning that there does not exist
any sequence $(x_i)_{i \geq 0}$ of elements of the abstract domain $A$ such that
$\forall i \geq 0,\ x_i <_A x_{i+1}$. Indeed, otherwise, the least fixpoint
computation could run indefinitely, since the ascending sequence of elements of
$A$ is infinite, and the fixpoint in never reached.


Many of the domains that are used for program analysis, including those of
intervals and convex polyhedra, do not satisfy this ascending chain condition. To ensure convergence in this case, another approximation
is performed: a new operator is defined, called \emph{widening operator}, that
extrapolates the limit of a sequence of abstract values
\cite{CC77,CousotCousot92-4}. This \emph{widening
operator} is usually noted $\widening: A \times A \rightarrow A$, and satisfies
the following properties:

\begin{itemize}
\item $\forall x_1, x_2 \in A,\ x_1 \leq_A x_1 \widening x_2$ and $x_2 \leq_A x_1
\widening x_2$. This guarantees the correctness of the result. Most of the time,
this operator is only defined for $x_1 \leq x_2$. In this case, we use $x_1
\widening (x_1 \sqcup x_2)$ instead.
\item For any increasing sequence $x_0 \leq_A x_1 \leq_A \dots$, the sequence
defined by 
$$\system{
x'_0 & = &  x_0 \\
x'_{i+1} & = &  x'_i\ \widening\ x_{i+1},\ \  \forall i \geq 0
}$$
is not strictly increasing. Then, applying the widening operator when the
sequence may increase indefinitely makes the computation converge to a fixpoint
in finite time. 
\end{itemize}

\cite{Monniaux_HOSC09} gives a more general definition of the widening operator.

The least fixpoint of a function $\Phi^\#$ is noted $\overline{x}$.
Instead of computing this least fixpoint,
one compute an upper approximation of it, by computing the following ascending
sequence:

$$\system{
x'_0 &=& \perp \\
x'_{i+1} &=& x'_i\ \widening\ ( x'_i \sqcup \Phi^\#(x'_i)),\ \ \forall i \geq 0
}$$

which converges towards $\tilde{x}$, where $\tilde{x} \geq_A \overline{x}$.

$\tilde{x}$ is a correct upper approximation of the least fixpoint of $\Phi^\#$,
and the classical technique is to regain some precision lost by the widening
operator by computing a descending sequence:

$$\system{
x''_0 &=& \tilde{x} \\
x''_{i+1} &=& \Phi^\#(x''_i), \ \ \forall i \geq 0
}$$

Each element of this descending sequence is still an upper approximation of the
least fixpoint $\overline{x}$. So, this sequence often allows to find
approximate least fixpoints that are more precise than the one obtained after
the ascending sequence.

\section{Linear Relation Analysis}

Linear Relation Analysis \cite{CH78} (also denoted LRA) is a direct application
of
Abstract Interpretation. It is aimed at computing an upper approximation of the
reachable states of a program containing numerical variables. The set of
possible assignments for the numerical variables is abstracted by a convex
polyhedron. This technique discovers invariant linear relations between
the numerical variables at each control point of a program.

This technique is:
\begin{itemize}
\item \emph{sound}: Each possible assignment for the variables in the real
program is included in the abstract value.
\item \emph{incomplete}: The abstract value also contains assignments for the
variables that are not possible in the real program.
\end{itemize}

\subsection{Convex polyhedra}

Let $x_1, x_2, \dots ,x_n$ be the numerical variables of a program (assume they
 are all in $\Q$). A state of
the program is then a point $\overrightarrow{x} \in \Q^n$.

In $\Q^n$, the set of polyhedra ordered by inclusion is a lattice. The least element is $\perp$
(the empty polyhedron), and the greatest element is $\top$ (the whole $Q^n$).

The classical union of two convex polyhedra may not be a convex polyhedron.
Therefore, we use the convex hull operation, noted $\sqcup$, for joining
polyhedra. 
If $X_1, X_2$ are two convex polyhedra, $X_1 \sqcup X_2$ is the
smallest convex polyhedron containing both $X_1$ and $X_2$.

Since the domain of convex polyhedra is of infinite height, a widening operator
is defined to ensure convergence of the technique. 
Intuitively, the polyhedron $P \widening Q$ is obtained after 
removing from the system of linear equations defining $P$ all the inequalities
that are not satisfied by $Q$ (the actual definition is somewhat more involved,
see e.g. \cite{BagnaraHRZ05SCP}).
For instance, if $P = \{(x,y)\ |\ 0 \leq x \leq y \leq 1 \}$ and $Q = 
\{(x,y)\ |\ 0 \leq x \leq y \leq 2 \}$, then the result of the widening operator
will be $P \widening Q = \{(x,y)\ |\ 0 \leq x \leq y \}$.

There have been various
work proposing a definition or a refinement of the widening operator in LRA
\cite{CH78,Hal79,HPR97,BlanchetCousotEtAl_PLDI03}, in order to fight
against loss of precision:
\begin{itemize}
\item \emph{Delayed widening}: instead of applying widening at the first
iteration of the analysis, one apply it after a number $n$ of iterations. During
the $n-1$ first iterations, only a convex hull is computed. In some cases,
delaying the widening operation is more precise. The algorithm still terminates,
since widening is applied within a finite time after $n$ iterations. In most of
the cases, $n$ can be chosen equal to $2$.
\item \emph{Widening with threshold (or ``up to'')}: In some cases, instead of
brutally applying the widening operator, a fixed set of linear inequalities $T$
can be chosen, and the widening operator $\widening_T$ is defined as follows:
$P \widening_T Q$ is the intersection of $P \widening Q$ with all the inequalities in
$T$ satisfied by both $P$ and $Q$.

For instance, consider the program:
\begin{C}
while (x <= 50) {
	x++;
	y++;
}
\end{C}
If $P = \{(x,y)\ |\ 0 \leq x \leq y \leq 1 \}$, after one iteration of the loop,
we have 
\\$Q = \{(x,y)\ |\ 0 \leq x \leq y \leq 2 \}$. Instead of a classic
widening (which gives the result $P \widening Q = \{(x,y)\ |\ 0 \leq x \leq y \}$),
a widening with the threshold $x \leq 50$ gives 
$P \widening_T Q = \{(x,y)\ |\ 0 \leq x \leq y \leq 50\}$. In such cases, widening
with threshold helps to find better invariants.
\end{itemize}

\subsection{Program Analysis}

Throughout the report, a program will be represented by a control flow graph:
\begin{itemize}
\item $P$ is a finite set of control points.
\item $I_p$ is the (possibly empty)
set of initial values for each control point $p \in P$. For an initial control
point $p$, i.e a starting point of the program, $I_p$ is not empty. It is empty
in the other case.
\item $E \subseteq  P \times P$ is a set of directed edges. Each edge $e \in E$
has a semantics $\tau_e: \P(\Q^n) \rightarrow \P(\Q^n)$, $\P(\Q^n)$ being the
set
of possible values of $\overrightarrow{x}$. $\tau_e$ maps a set of states before
the transition to the set of states after the transition.
\end{itemize}

\begin{figure}[!h]
   \begin{minipage}[c]{.46\linewidth}
\begin{C}
x = 0;
y = 0;
while (true) {
	if (x <= 50) 
		y++;
	else 
		y--;
	if (y < 0) break;
	x++;
}
\end{C}
   \end{minipage} \hfill
   \begin{minipage}[c]{.46\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.5cm,
                    semithick,font=\footnotesize]

	\node[state] (n0) {$p_0$};
	\node[state] (n1) [below of=n0] {$p_1$};
	\node[state] (n2) [below left of=n1] {$p_2$};
	\node[state] (n3) [below right of=n1] {$p_3$};
	\node[state] (n4) [below left of=n3] {$p_4$};
	\node[state] (n5) [below of=n4] {$p_5$};
	\node[state] (n6) [below of=n5] {$p_6$};
	\node[state] (n7) [left of=n6] {$p_7$};

	\node (n8) [right of=n6] {};
	\node (n9) [right of=n1] {};

  \path [transition] 
		(n0) edge              node {$x,y \leftarrow 0$} (n1);
  \path [transition] 
        (n1) edge			   node [left] {$x \leq 50$} (n2);
  \path [transition] 
        (n1)  edge              node [right] {$x \geq 51$} (n3);
  \path [transition] 
        (n2) edge              node [left] {$y \leftarrow y+1$} (n4);
  \path [transition] 
        (n3) edge			   node [right] {$y \leftarrow y-1$} (n4);
  \path [transition] 
        (n4) edge			   node {$y \geq 0$} (n5);
  \path [transition] 
		(n4) edge  [out = 180, in=90] node [left] {$y \leq -1$} (n7);
  \path [transition] 
        (n5) edge              node {$x \leftarrow x+1$} (n6);
  \path [transition] 
        (n6) edge [out=0, in=0, distance=3.5cm] node {} (n1);

\end{tikzpicture}
   \end{minipage}
   \caption{Example of program, and its associated control flow graph. This
   program comes from \cite{GopanR06}.}
\label{runningexample}
\end{figure}
\FloatBarrier

To each state $p \in P$ of the control flow graph, we associate an abstract
value $X_p \in D$, $D$ being in our case the domain of convex polyhedra over
$\Q^n$. Since the exact operation $\tau$ may not be expressible in the abstract
domain, we abstract it into $\tau^\#$ such that $\forall X \in D, \tau(X)
\subseteq \tau^\#(X)$. 

The computation is aimed at finding a solution for this system of abstract semantic
inequalities:

$$\system{
\forall p \in P, \ \ I_p \subseteq X_p \\
\forall (p',p) \in E,\ \  \tau^\#_{(p',p)}(X_{p'}) \subseteq X_p
}$$

\begin{figure}[h!]
\centering
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,
                    semithick]

  \node[state] (p)             [label=left:$X_{p}$]       {$p$};
  \node[state]         (p2) [above  of=p] {};
  \node[state]         (p1) [left of=p2,label=left:$X_{p'}$] {$p'$};
  \node[state]         (p3) [right of=p2] {};
  \node         (p22) [below  of=p] {};
  \node         (p12) [left of=p22] {};
  \node         (p32) [right of=p22] {};

  \path [transition] (p1) edge              node {} (p);
  \path [transition] (p2) edge              node {} (p);
  \path [transition] (p3) edge              node {} (p);
  \path [transition2] (p) edge              node {} (p12);
  \path [transition2] (p) edge              node {} (p22);
  \path [transition2] (p) edge              node {} (p32);
\end{tikzpicture}
\end{figure}

The function $\Phi^\#$ previously described is the following:

$$\Phi^\#\left[ \begin{array}{c}
\vdots \\
X_p \\
\vdots
\end{array} \right] = \left[ \begin{array}{c} 
\vdots \\
I_p \sqcup \displaystyle \bigsqcup_{(p',p) \in E} \tau^\# (X_{p'}) \\
\vdots
\end{array} \right]$$

The fixpoint computation algorithm consists in replacing iteratively each $X_p$ by its value
on the right hand side, until the convergence.

In the case of an abstract domain with infinite ascending sequence, we use the
previously defined widening operator:

$$\left[ \begin{array}{c}
\vdots \\
X_p \\
\vdots
\end{array} \right] \longleftarrow \left[ \begin{array}{c} 
\vdots \\
X_p \widening \left( I_p \sqcup \displaystyle \bigsqcup_{(p',p) \in E} \tau^\#
(X_{p'}) \right) \\
\vdots
\end{array} \right]$$


After a finite number of steps, the computation has reached the fixpoint and the
value $X_p$ at the end gives various linear relations between the
different numerical variables of the program at the control point $p$.

\subsection{Precision of the analysis}
In order to guarantee the termination of the computation, there is no need to
apply the widening operator at each control point $p \in P$. It is sufficient to
apply it on a subset of $P$, called $P_w$, such that removing the nodes of $P_w$
disconnects every cycles. For instance, $P_w$ can be chosen as the set of the
loop headers.

\subsubsection{Iteration strategies}
There exist several iteration strategies for computing the fixpoint: whatever
order we choose for updating the different $X_p, p\in P$, the result at the
end of the analysis is correct. Yet, the precision of the result and the time
before convergence can be very different. 
There have been some work to find efficient iteration strategies
\cite{Bou92}, such as first stabilising innermost loops, or stabilising strongly
connected components of the graph.

\subsubsection{Sources of imprecision}
 \label{imprecision}
Linear Relation Analysis is sound but incomplete: there is loss of precision
during the computation, due to various reasons:
\begin{enumerate}
\item Since an abstract domain is used to represent the set of possible states,
such as the domain of convex polyhedra, there is an upper approximation of the
set of possible states to the smallest convex polyhedron including this set. This
loss of precision is unavoidable. Still, there are techniques proposing to
compute disjunctive invariants \cite{GulwaniZ10} to limit this upper approximation: at each
program point, a union of convex polyhedra is computed instead of a single
one.
\item The widening operator, used to ensure convergence of the technique,
also induces a loss of precision. The classical technique is then to compute
narrowing iterations, which often recover some precision. 

For instance, considering the program:
\begin{C}
for (int i=0; i < 100; i++) {
}
\end{C}
The analysis starts with $i=0$. After one iteration, $i \in
[0,1]$, then $i\in [0,2]$ after the second iteration\dots. 
After a widening operation, the result becomes $i \in [0,
+\infty]$, which is an invariant, but very imprecise. We can do a new iteration,
with $i\in [0, +\infty]$ at the beginning of the loop, and we find that the
values for $i$ at the next step are in $[0, 100]$. This is still an invariant,
but much better. We can repeat such iterations as long as the set narrows, and
we always obtain a correct over-approximation.
In practise, a single narrowing iteration is enough to recover the precision.

\item There is also a loss of precision each time a point in the control flow
graph has several incoming edges. This is the case for instance for
\emph{if} statements, loops, etc. In this case, the abstract value of this point
is a convex hull of several convex polyhedra, inducing an upper approximation.
Indeed, if $X_1, X_2$ are convex polyhedra,
$$X_1 \cup X_2 \subseteq X_1 \sqcup X_2$$

To limit the number of such points, a method could be
to expand the control flow graph. For instance, instead of considering a graph
with a sequence of $n$ \emph{if-then-else} between points $p_1$ and $p_n$, 
the $n$ merge node
of these \emph{if-then-else} could be removed, each of them having two incoming
edges, and 
$2^n$ edges from $p_1$ to $p_n$ are added, corresponding to the different paths through
the \emph{if-then-else} statements. At the end, $p_n$ is the only point with
several incoming edges. This graph transformation results in an exponential
blowup, because of the exponential growth of the number of edges in the graph.
\end{enumerate}


\subsubsection{Acceleration}

Typically, to analyse a program with loops, the approach is to use the
widening operator, for example at the head of the loops, to ensure convergence.
Since this induces imprecision, another technique called \emph{acceleration}
is aimed at computing the exact effect of the loop when possible \cite{Gon07,GH06}. For instance, for
the following program, an invariant could be directly computed for the loop:


\begin{minipage}[c]{.39\linewidth}
\begin{C}
x = 0;
y = 0;
while (x < N) {
	y = y+2;
	x = x+5;
}
\end{C}
\end{minipage} 
\begin{minipage}[c]{.59\linewidth}
$$\begin{array}{llll}
\exists k \geq 0,& & x  = k \\
		&\wedge & y = 2k \\
		&\wedge & \forall k', (0 \leq k' \leq k)
				\Rightarrow (5k' \leq N)
\end{array}$$
\end{minipage}

Acceleration is possible when the loop is simple enough, and comes to compute
the transitive closure $\tau_e^+$ of $\tau_e$, the transition function
associated to the loop.

\section{Example}

We apply the linear relation analysis technique over the program in figure
\ref{runningexample}. The set of state where we apply widening is $\{p_1\}$: it
is sufficient, since removing $p_1$ cuts all cycles in the graph.

To each point of the control flow graph $\{p_0, p_1,\dots, p_7\}$, we attach a
convex polyhedron, whose dimensions are the numerical variables $x,y$.
For instance, at point $p_1$, the effective set of possible assignments for
$(x,y)$ is the union of the two segments $(0,0) - (51,51)$ and $(51,51) -
(102,0)$, depicted in figure \ref{result}.a. Since this union of segments is not
a convex polyhedron, the best result we can wait for after abstraction is the
polyhedron depicted in figure \ref{result}.b, which is the smallest convex
polyhedron containing the two segments.

\begin{figure}[!h]
\begin{minipage}[c]{.39\linewidth}
\centering
\begin{tikzpicture}[y=.2cm, x=.2cm,font=\footnotesize]

	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,0) -- (8,8) -- cycle;
	\draw[line] (16,0) -- (8,8) -- cycle;
	
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);

	%ticks and labels      
     		\draw [dotted](8,8) -- (-3pt,8) 
     			node[anchor=east] {$51$}; 
     		\draw [dotted] (8,8) -- (8,-3pt) 
     			node[anchor=north] {$51$}; 
     		\draw [dotted] (16,1pt) -- (16,-3pt) 
     			node[anchor=north] {$102$}; 

	\node[right=1.9cm] at (x axis mid) {$x$};
	\node[above=1.2cm] at (y axis mid) {$y$};

	\node[right=3cm] at (y axis mid) {$p_1$};
\end{tikzpicture}

a. During execution, $(x,y)$ can only be in one of these two segments.
\end{minipage} 
\begin{minipage}[c]{.59\linewidth}
\centering
\begin{tikzpicture}[y=.2cm, x=.2cm,font=\footnotesize]

	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,0) -- (8,8) -- cycle;
	\draw[line] (16,0) -- (8,8) -- cycle;
	
	\fill[polyhedra] (0,0) -- (8,8) -- (16,0) -- cycle;

 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);

	%ticks and labels      
     		\draw [dotted](8,8) -- (-3pt,8) 
     			node[anchor=east] {$51$}; 
     		\draw [dotted] (8,8) -- (8,-3pt) 
     			node[anchor=north] {$51$}; 
     		\draw [dotted] (16,1pt) -- (16,-3pt) 
     			node[anchor=north] {$102$}; 

	\node[right=1.9cm] at (x axis mid) {$x$};
	\node[above=1.2cm] at (y axis mid) {$y$};

	\node[right=3cm] at (y axis mid) {$p_1$};
\end{tikzpicture} 

b. The best result we can have is the polyhedron in hashed lines.
\end{minipage}
\caption{Best results we can get from the analysis}
\label{result}
\end{figure}

We apply abstract interpretation to this program. Let $X_i$ be the polyhedron
attached to point $p_i$. Initially, $X_i = \perp$ for each $i \in \{1,7\}$, and
$X_0 = \top$. The tabular in figure \ref{iterations} shows the evolution of the
polyhedra during the iterations.

After 3 iterations, we have reached an invariant. We can then apply a narrowing
iteration, that recovers some precision. Finally, at point $p_1$, we see that
the obtained result is not as precise as we could wish (Figure \ref{result}.b).
This is due to the widening operator applied at point $p_1$, and the convex hull
applied at point $p_4$.

\begin{figure}[!h]
\centering
\caption{Polyhedron attached to the different points during iterations.}
\label{iterations}
\begin{tabular}{|c||c|c|c|c|} \hline
Iteration & $X_0 \sqcup X_6$ & $X_1$ (widening) & $X_4$ & $X_6$ \\ \hline
1& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\fill[line] (0,0) circle (0.8);
	%\draw[line] (0,0) -- (8,8) -- cycle;
	%\draw[line] (16,0) -- (8,8) -- cycle;
	%\fill[polyhedra] (0,0) -- (8,8) -- (16,0) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
&
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\fill[line] (0,0) circle (0.8);
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\fill[line] (0,2) circle (0.8);
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
     		\draw [dotted](1pt,2) -- (-3pt,2) 
     			node[anchor=east] {$1$}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\fill[line] (2,2) circle (0.8);
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
     		\draw [dotted](2,2) -- (-3pt,2) 
     			node[anchor=east] { {\tiny $1$}}; 
     		\draw [dotted](2,2) -- (2,-3pt) 
     			node[anchor=north] { {\tiny $1$}}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
\\ \hline
2&
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,0) -- (2,2) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
     		\draw [dotted](2,2) -- (-3pt,2) 
     			node[anchor=east] { {\tiny $1$}}; 
     		\draw [dotted](2,2) -- (2,-3pt) 
     			node[anchor=north] { {\tiny $1$}}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,0) -- (12,12) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
&
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,2) -- (6,8) -- cycle;
	\draw[line] (8,6) -- (14,12) -- cycle;
	\fill[polyhedra] (0,2) -- (10,12) -- (14,12) -- (8,6) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
	     	\draw [dotted](6,8) -- (-3pt,8) 
     			node[anchor=east,yshift=2pt] { {\tiny $51$}}; 
     		\draw [dotted] (8,6) -- (-3pt,6) 
     			node[anchor=east, yshift=-2pt] { {\tiny $50$}}; 
     		\draw [dotted](8,6) -- (8,-3pt) 
     			node[anchor=north,xshift=2pt] { {\tiny $51$}}; 
     		\draw [dotted] (6,8) -- (6,-3pt) 
     			node[anchor=north,xshift=-2pt] { {\tiny $50$}};
     		\draw [dotted](1pt,2) -- (-3pt,2) 
     			node[anchor=east] { {\tiny $1$}}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
&
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	%\draw[line] (2,2) -- (6,8) -- cycle;
	%\draw[line] (8,6) -- (14,12) -- cycle;
	\fill[polyhedra] (2,2) -- (12,12) -- (16,12) -- (10,6) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
     		\draw [dotted] (10,6) -- (-3pt,6) 
     			node[anchor=east, yshift=-2pt] { {\tiny $50$}}; 
     		\draw [dotted](10,6) -- (10,-3pt) 
     			node[anchor=north,xshift=2pt] { {\tiny $52$}}; 
     		\draw [dotted](2,2) -- (-3pt,2) 
     			node[anchor=east] { {\tiny $1$}}; 
     		\draw [dotted](2,2) -- (2,-3pt) 
     			node[anchor=north] { {\tiny $1$}}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
\\ \hline
3& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	%\draw[line] (2,2) -- (6,8) -- cycle;
	%\draw[line] (8,6) -- (14,12) -- cycle;
	\fill[polyhedra] (0,0) -- (12,12) -- (16,12) -- (10,6) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
     		\draw [dotted] (10,6) -- (-3pt,6) 
     			node[anchor=east, yshift=-2pt] { {\tiny $50$}}; 
     		\draw [dotted](10,6) -- (10,-3pt) 
     			node[anchor=north,xshift=2pt] { {\tiny $52$}}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (-4,-4) -- (12,12) -- cycle;
	\fill[polyhedra] (-4,-4) -- (12,12) -- (20,12) -- (20,-4) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (-4,-2) -- (10,12) -- cycle;
	\fill[polyhedra] (-4,-4) -- (-4,-2) -- (10,12) -- (20,12) -- (20,-4) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
     		\draw [dotted](1pt,2) -- (-3pt,2) 
     			node[anchor=east] { {\tiny $1$}}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
&
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,0) -- (12,12) -- cycle;
	\fill[polyhedra] (0,0) -- (12,12) -- (20,12) -- (20,0) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
\\ \hline
narrowing& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,0) -- (12,12) -- cycle;
	\fill[polyhedra] (0,0) -- (12,12) -- (20,12) -- (20,0) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,0) -- (12,12) -- cycle;
	\fill[polyhedra] (0,0) -- (12,12) -- (20,12) -- (20,0) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (0,2) -- (10,12) -- cycle;
	\draw[line] (0,2) -- (10,-2) -- cycle;
	\draw[line] (20,-2) -- (10,-2) -- cycle;
	\fill[polyhedra] (0,2) -- (10,12) -- (20,12) -- (20,-2) --
	(10,-2) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
     		\draw [dotted](1pt,2) -- (-3pt,2) 
     			node[anchor=east] { {\tiny $1$}}; 
     		\draw [dotted](10,-2) -- (-3pt,-2) 
     			node[anchor=east] { {\tiny $-1$}}; 
     		\draw [dotted](10,-2) -- (10,1pt) 
     			node[anchor=south] { {\tiny $51$}}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
& 
\begin{tikzpicture}[y=.1cm, x=.1cm,font=\footnotesize]
	\node (t1) at (-5,-4) {};
	\node (t2) at (13,11) {};
	\draw[line] (2,2) -- (12,12) -- cycle;
	\draw[line] (2,2) -- (7,0) -- cycle;
	\fill[polyhedra] (2,2) -- (12,12) -- (20,12) -- (20,0) --
	(7,0) -- cycle;
 	%axis
	\draw (0,0) -- coordinate (x axis mid) (20,0);
    \draw (0,0) -- coordinate (y axis mid) (0,10);
	%ticks and labels      
     		\draw [dotted](2,2) -- (-3pt,2) 
     			node[anchor=east] { {\tiny $1$}}; 
     		\draw [dotted](2,2) -- (2,-3pt) 
     			node[anchor=north] { {\tiny $1$}}; 
	\node[right=0.9cm] at (x axis mid) {$x$};
	\node[above=0.6cm] at (y axis mid) {$y$};
\end{tikzpicture} 
\\ \hline
\end{tabular}
\end{figure}

\chapter{Path Focusing technique} \label{pathfocusingpart}
 
	In this part, we present two techniques that aim to isolate the different
	paths of the program to compute more precise invariants.

 \section{Lookahead Widening}

In some cases, a loop can have a non-regular behaviour, especially when it has
several paths. Some of these paths can stay impossible for a while, and become
possible after a certain number of iterations. However, the widening operator
extrapolates without taking care of these new possible paths. This can induce a
loss of precision, that \emph{Lookahead widening} tries to limit.

Lookahead widening \cite{GopanR06} is a technique that isolates the
different loop phases during the analysis, and stabilises each of these loop
phases before proceeding to the next. One only consider paths that are feasible
at the first iteration, and forget the others for a while. The iterations end
when the analysis of these paths has converged. After that, some
narrowing iterations can be computed. Then, paths that
become feasible are reinserted into the control flow graph, and we redo
iterations.

In the program already depicted in figure \ref{runningexample}, there is a loop
with two perfectly distinct phases:
\begin{itemize}
\item During the 51 first iterations, both $x$ and $y$ are incremented.
\item During the 51 last iterations, $x$ is incremented and $y$ is decremented.
\end{itemize}

When computing the fixpoint iterations, we only consider a subset of the graph
for a while, until the convergence. In our example:
\begin{itemize}
\item Step 1:
	we only consider the path of
	the loop that is possible at the first iteration. The second path is
	ignored, and will be treated later. We compute the iterations, and we obtain
	an first invariant for this part of the graph: at point $p_1$, $x =
	y \wedge x \geq 0$.
	Then, we can do some
	narrowing steps in order to recover some precision, before adding new paths
	in the graph. At point $p_1$ after narrowing, $x=y \wedge 0 \leq x \leq 51$.
\item Step 2:
	Now, we add the new paths into our graph if they have become possible. In
	our case, the second path of the loop is now possible, because $x$ can be
	equal to $51$, so we add the path in
	the graph and compute new iterations until convergence\dots. After
	convergence, at point $p_1$, $x + y - 102 \leq 0 \wedge x
	\leq y$. We then apply a narrowing step and at $p_1$, 
$x + y - 102 \leq 0 \wedge x \leq y \wedge y \geq 0$.
\item Step 3: finally, the path from $p_4$ to $p_7$ becomes possible, so we add
it into the graph and compute the invariant for $p_7$.
\end{itemize}

Finally, at $p_1$, the result we obtain is the best we can have using convex
polyhedra (see Figure \ref{result}.b). This method allows to find the
constraint $x + y - 102 \leq 0$, which is not the case in the classical abstract
interpretation technique.

\begin{figure}[!h]
   \begin{minipage}[c]{.46\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.5cm,
                    semithick,font=\footnotesize]

	\node[state] (n0) {$p_0$};
	\node[state] (n1) [below of=n0] {$p_1$};
	\node[state] (n2) [below left of=n1] {$p_2$};
	\node[state] (n3) [below right of=n1] {$p_3$};
	\node[state] (n4) [below left of=n3] {$p_4$};
	\node[state] (n5) [below of=n4] {$p_5$};
	\node[state] (n6) [below of=n5] {$p_6$};
	\node[state] (n7) [left of=n6] {$p_7$};

	\node (n8) [right of=n6] {};
	\node (n9) [right of=n1] {};

  \path [transition] 
		(n0) edge              node {$x,y \leftarrow 0$} (n1);
  \path [transition] 
        (n1) edge			   node [left] {$x \leq 50$} (n2);
  \path [transition2] 
        (n1)  edge              node [right] {$x \geq 51$} (n3);
  \path [transition] 
        (n2) edge              node [left] {$y \leftarrow y+1$} (n4);
  \path [transition2] 
        (n3) edge			   node [right] {$y \leftarrow y-1$} (n4);
  \path [transition] 
        (n4) edge			   node {$y \geq 0$} (n5);
  \path [transition2] 
		(n4) edge  [out = 180, in=90] node [left] {$y \leq -1$} (n7);
  \path [transition] 
        (n5) edge              node {$x \leftarrow x+1$} (n6);
  \path [transition] 
        (n6) edge [out=0, in=0, distance=3.5cm] node {} (n1);

\end{tikzpicture}
\centering Step 1
   \end{minipage} \hfill
   \begin{minipage}[c]{.46\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.5cm,
                    semithick,font=\footnotesize]

	\node[state] (n0) {$p_0$};
	\node[state] (n1) [below of=n0] {$p_1$};
	\node[state] (n2) [below left of=n1] {$p_2$};
	\node[state] (n3) [below right of=n1] {$p_3$};
	\node[state] (n4) [below left of=n3] {$p_4$};
	\node[state] (n5) [below of=n4] {$p_5$};
	\node[state] (n6) [below of=n5] {$p_6$};
	\node[state] (n7) [left of=n6] {$p_7$};

	\node (n8) [right of=n6] {};
	\node (n9) [right of=n1] {};

  \path [transition] 
		(n0) edge              node {$x,y \leftarrow 0$} (n1);
  \path [transition] 
        (n1) edge			   node [left] {$x \leq 50$} (n2);
  \path [transition] 
        (n1)  edge              node [right] {$x \geq 51$} (n3);
  \path [transition] 
        (n2) edge              node [left] {$y \leftarrow y+1$} (n4);
  \path [transition] 
        (n3) edge			   node [right] {$y \leftarrow y-1$} (n4);
  \path [transition] 
        (n4) edge			   node {$y \geq 0$} (n5);
  \path [transition2] 
		(n4) edge  [out = 180, in=90] node [left] {$y \leq -1$} (n7);
  \path [transition] 
        (n5) edge              node {$x \leftarrow x+1$} (n6);
  \path [transition] 
        (n6) edge [out=0, in=0, distance=3.5cm] node {} (n1);

\end{tikzpicture}
\centering Step 2
   \end{minipage}
   \caption{Dotted arrows are ignored by the analysis.}
\label{gopanreps}
\end{figure}
\FloatBarrier

In the classical abstract interpretation technique, narrowing iterations are
computed at the end of the analysis, when all the fixpoint computation has
converged.
The interest of this method is to apply narrowing iterations right after each
path computation. This allows to recover precision before analysing new paths,
and then to be more precise. 

 \section{Path Focusing}

	\subsection{Multigraph}

	\subsubsection{Expanding the control flow graph}
	The main idea of the technique is to compute the fixpoint iterations on an
	expanded multigraph instead of the classical control flow graph. A
	multigraph is a graph that can have several edges from a point $p$ to a
	point $q$. 

	Intuitively, expanding the graph comes back to consider independently the
	different paths in the control flow graph, and thus to be more precise,
	because paths that are not feasible will be ignored. Additionally, the
	number of control points with several incoming transitions will be reduced,
	so the loss of precision due to the convex hull of polyhedra may be
	minimised.

\begin{figure}[!h]
\label{multigraph}
\centering
\begin{minipage}[c]{.19\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.1cm,
                    semithick,font=\footnotesize]

	\node[PRstate] (n0) {$p$};
	\node[state] (n1) [below left of=n0] {};
	\node[state] (n2) [below right of=n0] {};
	\node[state] (n3) [below right of=n1] {};
	\node[state] (n4) [below left of=n3] {};
	\node[state] (n5) [below right of=n3] {};
	\node[state] (n6) [below right of=n4] {};
	\node[state] (n7) [below left of=n6] {};
	\node[state] (n8) [below right of=n6] {};
	\node[PRstate] (n9) [below right of=n7] {$q$};

  \path [transition] 
		(n0) edge              node {} (n1);
  \path [transition] 
		(n0) edge              node {} (n2);
  \path [transition] 
		(n1) edge              node {} (n3);
  \path [transition] 
		(n2) edge              node {} (n3);
  \path [transition] 
		(n3) edge              node {} (n4);
  \path [transition] 
		(n3) edge              node {} (n5);
  \path [transition] 
		(n4) edge              node {} (n6);
  \path [transition] 
		(n5) edge              node {} (n6);
  \path [transition] 
		(n6) edge              node {} (n7);
  \path [transition] 
		(n6) edge              node {} (n8);
  \path [transition] 
		(n7) edge              node {} (n9);
  \path [transition] 
		(n8) edge              node {} (n9);
\end{tikzpicture}
\end{minipage} 
$\Longrightarrow$
\begin{minipage}[c]{.19\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.1cm,
                    semithick,font=\footnotesize]

	\node[PRstate] (n0) {$p$};
	\node (n1) [below left of=n0] {};
	\node (n2) [below right of=n0] {};
	\node (n3) [below right of=n1] {};
	\node (n4) [below left of=n3] {};
	\node (n5) [below right of=n3] {};
	\node (n6) [below right of=n4] {};
	\node (n7) [below left of=n6] {};
	\node (n8) [below right of=n6] {};
	\node[PRstate] (n9) [below right of=n7] {$q$};

  \path [transition] 
		(n0) edge  [out=0, in=0]            node {} (n9);
  \path [transition] 
		(n0) edge  [out=180, in=180]        node {} (n9);
  \path [transition] 
		(n0) edge  [out=205, in=155]            node {} (n9);
  \path [transition] 
		(n0) edge  [out=230, in=130]            node {} (n9);
  \path [transition] 
		(n0) edge  [out=255, in=105]            node {} (n9);
  \path [transition] 
		(n0) edge  [out=-25, in=25]            node {} (n9);
  \path [transition] 
		(n0) edge  [out=-50, in=50]            node {} (n9);
  \path [transition] 
		(n0) edge  [out=-75, in=75]            node {} (n9);
\end{tikzpicture}
\end{minipage}
\caption{One can expand the graph in the left and obtain the associated graph in
the right.}
\end{figure}
\FloatBarrier

	Let $(P,E)$ be the control flow graph of the program.
	First, one chooses a set of widening points $P_W \subseteq P$, so that the graph
	obtained after removing these points has no cycle. The widening operator
	will be applied at these points. The choice of $P_W$ can be guided by
	\cite{Bou92}.
	Then, another set $P_R \subseteq P$ of nodes is chosen, satisfying the
	following properties:
	\begin{itemize}
	\item $I_p = \emptyset$ for each $p \in P \setminus P_R$, meaning that the initial
	points of the program are included in $P_R$.
	\item $P_W \subseteq P_R$: all the widening points are in $P_R$.
	\end{itemize} 

	The multigraph is then the graph such that:
	\begin{itemize}
	\item each element of $P_R$ is a point of the graph.
	\item for each path $p_1 \rightarrow p_2 \rightarrow \dots \rightarrow p_k$
	in the control flow graph, such that $p_1 \in P_R, p_k \in P_R$,
	there is a transition in the multigraph from $p_1$ to $p_k$ with the
	semantic $$\tau_{p_1 \rightarrow \dots \rightarrow p_k} = \tau_{p_{k-1}
	\rightarrow p_k} \circ
	\dots \circ \tau_{p_1 \rightarrow p_2}$$ where $\tau_{p_i \rightarrow
	p_{i+1}}$ is the transformation associated to the semantic of $p_i
	\rightarrow p_{i+1}$.
	\end{itemize}

	As explained in \ref{imprecision}, separating the different
	possible paths between $p$ and $q$ reduce the number of points with a join
	operation, and results in a better precision.
	This can result in an exponential blowup in the size of the graph. To avoid
	it, the technique is to never construct the multigraph, and only compute
	parts of it when needed.

	Intuitively, choosing a small set $P_R$ will result in a better precision,
	but a higher cost. 
	Indeed, the number of paths between two points of $P_R$ will grow if $P_R$
	contains few elements.
	A good choice for $P_R$ requires to find a good
	compromise between precision and cost of the technique.

\begin{figure}[!h]
\label{CFG}
\centering
\begin{minipage}[c]{.39\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.5cm,
                    semithick,font=\footnotesize]

	\node[PRstate] (n0) {$p_0$};
	\node[PRstate] (n1) [below of=n0] {$p_1$};
	\node[state] (n2) [below left of=n1] {$p_2$};
	\node[state] (n3) [below right of=n1] {$p_3$};
	\node[state] (n4) [below left of=n3] {$p_4$};
	\node[state] (n5) [below of=n4] {$p_5$};
	\node[state] (n6) [below of=n5] {$p_6$};
	\node[PRstate] (n7) [left of=n6] {$p_7$};


  \path [transition] 
		(n0) edge              node {$x,y \leftarrow 0$} (n1);
  \path [transition2] 
        (n1) edge			   node [left] {$x \leq 50$} (n2);
  \path [transition] 
        (n1)  edge              node [right] {$x \geq 51$} (n3);
  \path [transition2] 
        (n2) edge              node [left] {$y \leftarrow y+1$} (n4);
  \path [transition] 
        (n3) edge			   node [right] {$y \leftarrow y-1$} (n4);
  \path [transition2] 
        (n4) edge			   node {$y \geq 0$} (n5);
  \path [transition] 
		(n4) edge  [out = 180, in=90] node [left] {$y \leq -1$} (n7);
  \path [transition2] 
        (n5) edge              node {$x \leftarrow x+1$} (n6);
  \path [transition2] 
        (n6) edge [out=0, in=0, distance=3.5cm] node {} (n1);
\end{tikzpicture}
\end{minipage} 
$\Longrightarrow$
\begin{minipage}[c]{.49\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=3.2cm,
                    semithick,font=\footnotesize]

	\node[PRstate] (n0) {$p_0$};
	\node[PRstate] (n1) [below of=n0,yshift=1cm] {$p_1$};
	\node[PRstate] (n7) [below of=n1] {$p_7$};

	\node (n8) at (-3,0) {};
	\node (n8) at (3,0) {};

  \path [transition] 
		(n0) edge              node [yshift=5mm] {$x,y \leftarrow 0$} (n1);
  \path [transition] 
		(n1) edge    [bend left]  node [right,yshift=-0.8cm]  {$
		\begin{array}{l}
			x \geq 51 \\
			y \leq 0 \\
			y \leftarrow y-1
		\end{array}
		$} (n7);
  \path [transition2] 
		(n1) edge    [loop left,distance=1.2cm]  node [left,xshift=3mm] {$
		\begin{array}{l}
			x \leq 50 \\
			y \geq -1 \\
			y \leftarrow y+1 \\
			x \leftarrow x+1 
		\end{array}
		$} (n1);
  \path [transition] 
		(n1) edge    [loop right,distance=1.2cm]  node [right,xshift=-2mm] {$
		\begin{array}{l}
			x \geq 51 \\
			y \geq 1 \\
			y \leftarrow y-1 \\
			x \leftarrow x+1 
		\end{array}
		$} (n1);
  \path [transition] 
		(n1) edge    [bend right]  node [left,yshift=-0.8cm,xshift=4mm] {$
		\begin{array}{l}
			x \leq 50 \\
			y \leq -2 \\
			y \leftarrow y-1
		\end{array}
		$} (n7);
\end{tikzpicture}
\end{minipage}
\caption{Example of classical control flow graph, and its associated expanded
multigraph, where $P_R = \{p_0, p_1, p_7\}$. The path dashed from $p_1$ to $p_1$
in the control flow graph corresponds to a simple dashed transition in the multigraph,
having the same semantic.}
\label{multigraphtransformGopan}
\end{figure}
\FloatBarrier

%\begin{tikzpicture}[->,>=stealth',auto,node distance=1.5cm,
%                    semithick,font=\footnotesize]
%
%	\node[state] (n0) {$p_0$};
%	\node[state] (n1) [below of=n0] {$p_1$};
%	\node[state] (n2) [below left of=n1] {$p_2$};
%	\node[state] (n3) [below right of=n1] {$p_3$};
%	\node[state] (n4) [below left of=n3] {$p_4$};
%	\node[state] (n5) [below of=n4] {$p_5$};
%	\node[state] (n6) [below of=n5] {$p_6$};
%	\node[state] (n7) [left of=n6] {$p_7$};
%
%	\node (n8) [right of=n6] {};
%	\node (n9) [right of=n1] {};
%	\node (n88) [above right of=n8] {};
%	\node (n99) [below right of=n9] {};
%
%	\path[transition] plot[->,smooth,tension=0.7] coordinates {
%		(n1)
%		(n2)
%		(-0.4,-3.8)
%		(n7)
%	};
%	\path[transition] plot[->,smooth,tension=0.7] coordinates {
%		(n1)
%		(0.7,-2.6)
%		(0,-3.8)
%		(n7)
%	};
%	\path[transition] plot[->,smooth,tension=0.7] coordinates {
%		(n1)
%		(-0.8,-2.4)
%		(-0.1,-3.8)
%		(0,-6.3)
%		(2.5,-5.5)
%		(2.5,-2.5)
%		(n1)
%	};
%	\path[transition] plot[->,smooth,tension=0.7] coordinates {
%		(n1)
%		(n3)
%		(0.3,-3.8)
%		(0.3,-6)
%		(2.1,-5.5)
%		(2.1,-2.5)
%		(n1)
%	};
%
%  \path [transition] 
%		(n0) edge              node {$x,y \leftarrow 0$} (n1);
%
%	\node[state] (n0) {$p_0$};
%	\node[state] (n1) [below of=n0] {$p_1$};
%	\node[state] (n2) [below left of=n1] {$p_2$};
%	\node[state] (n3) [below right of=n1] {$p_3$};
%	\node[state] (n4) [below left of=n3] {$p_4$};
%	\node[state] (n5) [below of=n4] {$p_5$};
%	\node[state] (n6) [below of=n5] {$p_6$};
%	\node[state] (n7) [left of=n6] {$p_7$};
%
%\end{tikzpicture}
	
	\subsubsection{Static Single Assignment form}

	Path focusing technique uses control flow graphs in static single assignment
	(SSA) form. The main concept behind the SSA form is that, syntactically,
	every variable is	
	only being assigned once. 


\begin{figure}[!h]
\centering
\begin{minipage}[c]{.39\linewidth}
\begin{C}
x = 0;
y = 0;
x = x + 2;
y = x + 1;
\end{C}
\end{minipage} 
$\Longrightarrow$ \hfill
\begin{minipage}[c]{.49\linewidth}
\begin{C}
x.0 = 0;
y.0 = 0;
x.1 = x.0 + 2;
y.1 = x.1 + 1;
\end{C}
\end{minipage}
\caption{On the left side, a simple program. On the right side, the same
program in SSA form.}
\end{figure}

This single definition property cannot be achieved with only the renaming of
variables assigned most than once. In some cases, two distinct definition reach
the same use, depending on the actual execution. To solve this issue, SSA form
uses $\Phi$-functions.

A $\Phi$-function is usually inserted at points of the control flow graph that
have several incoming transitions, and has the same number of arguments as the point
has incoming transitions. Assuming these transitions are ordered, the
$\Phi$-function returns the value of its $i$-th argument if the point is reached
from the $i$-th transition.

\begin{figure}[!h]
\centering
\begin{minipage}[c]{.39\linewidth}
\begin{C}
if (c) x = 0;
else x = 1;

y = x+1;
\end{C}
\end{minipage} 
$\Longrightarrow$ \hfill
\begin{minipage}[c]{.49\linewidth}
\begin{C}
if (c) x.0 = 0;
else x.1 = 0;

x.2 = Phi (x.0, x.1)
y.0 = x.2 + 1;
\end{C}
\end{minipage}
\end{figure}
\FloatBarrier

This static single assignment form is used for the computation of the focus
path.

	\subsection{Choice of the focus paths}

	\subsubsection{Reachability problem}
	\label{reachability}
	Path focusing technique tries to discover which paths to focus on for the
	computation of the fixpoint iterations. 
	Since the multigraph is not constructed explicitly, the different paths
	starting and finishing on node in $P_R$ are not known. 
	The technique proposes to express the focus path as the solution of a
	satisfiability modulo theory (SMT) problem:

	\begin{center} \emph{
		``Is there a path starting on control point $p$, with numerical
		variables in $X_p$, that ends on point $q$, with variables that are not
		in $X_q$?''}
	\end{center}

	This problem could be rephrased as:
	``Is there a path that starts on $p$, that can make the fixpoint computation
	progress ?''
	Indeed, the idea is to only focus on paths that make the abstract values
	grow.

	This is a reachability problem, that can be expressed as an SMT-formula,
	which is a logic formula with Boolean variables, and elements of a certain
	theory $T$. Depending on the program, different theories may be used:
	\begin{itemize}
	\item For programs with rational variables, whose operations (instructions,
	transition conditions\dots) are all linear arithmetic, $T$ can be the theory
	of linear real arithmetic (LRA).
	\item For programs with integer variables (with a numerical state space in
	$\Z^n$) $T$ can be the theory of linear integer arithmetic (LIA).
	\end{itemize}

	Although deciding the satisfiability of such formula is NP-complete, there
	has been much research on decision procedures \cite{Kroening08} and there exist nowadays
	efficient programs, known as SMT-solvers, that can decide the satisfiability
	of LRA or LIA formulae. Well-known efficient SMT-solvers are
	Z3 \cite{MouraB08} and Yices \cite{DutertreM06}. 

	If the problem has a solution,  the SMT-solver will be in position to show
	which path in the control flow graph is selected, by giving a model: an
	assignments of the Boolean variables so that the formula is true.
	Among these Boolean variables, some of them are associated to a transition
	in the control flow graph:
	\begin{itemize}
	\item if the model has set to \emph{true} the Boolean variable $b_e$ associated
	to the transition $e$, then the focus path goes through this transition.
	\item in the other case, the focus path does not go through this transition.
	\end{itemize}
	
	Some others are associated to the points of the control flow graph. These
	are called \emph{reachability predicates}, and are set to \emph{true} in the
	model if and only if the focus path goes through these points.

	\subsubsection{Construction of the formula}
	The first point of the Path Focusing technique is to compute the SMT formula
	$\rho$ expressing the semantic of the program. For doing so, all the
	operations in the program have to be expressible within the theory we
	choose. Otherwise, the SMT-solver would not be able to decide if the formula
	is \emph{sat} or not.

	Since we want to find a path starting in a control point in $P_R$ and ending
	in a point in $P_R$, we need to disconnect in the formula the points $p_i$
	in $P_R$ into a source point $p_i^s$, with only outgoing transitions, and a
	destination point $p_i^d$, with only incoming transitions. 

	We construct the $\rho$ formula as follows:

\begin{enumerate}
\item Each numerical SSA variable of the control flow graph has its definition
in the $\rho$ formula.
\item For each operation in the program, we encode its semantic, expressed in
terms of the Boolean and numerical SSA variables. For instance, if the CFG
contains the assignment $x.2 = x.1 + 1$, then we simply add $x.2 = x.1 + 1$ in
the formula. This equality expression is noted $assign(x.2)$. 
$assign(x)$ is defined for each numerical SSA-variable of the program.
\item For each transition $(p_i,p_j) \in E$, we set $t_{i,j} = B_i\ \wedge \
c(i,j)$, where $B_i = b_i^s$ if $p_i \in P_R$, or $b_i$ if not.
$c(i,j)$ expresses the condition that needs to be true to go through the
transition. For instance, $c(i,j)$ could be of the form $x < y$, \dots
If the transition is non-deterministic, then $c(i,j) = c_{i,j}$, where
$c_{i,j}$ is a Boolean variable left non-deterministic.
\item For each point $p_i \notin P_R$, we set the reachability predicate 
$b_i = \displaystyle \bigvee_{(p_j,p_i)\in E} t_{j,i}$.
\item For each point $p_i^d \in P_R$, we set the reachability predicate 
$b_i^d = \displaystyle \bigvee_{(p_j,p_i)\in E} t_{j,i}$. 
\item Numerical $\Phi$-variables assignations have to be expressed in the $\rho$
formula. We simply use $\ite$ (\emph{if-then-else}) statements, a standard feature of the
SMT-Lib format \cite{BarST-SMTLIB}, for giving the right value to the variable,
depending on the incoming transition we come from. Generally, for a
$\Phi$-variable $x = \Phi(x_1,x_2,\dots,x_n)$ in control point $p_i$ with the
ordered incoming transitions $t_{j_1,i},t_{j_2,i},\dots,t_{j_n,i}$, we set:

$$x = \ite (t_{j_1,i})\  (x_1)\  (\ite (t_{j_2,i})\  (x_2)\  (\ite\  \dots))$$

where $\ite (c)\ (x)\ (y)$ is equal to $x$ if $c = true$, else $y$.

If the point where the $\Phi$-variable $x$ is defined is in
$P_R$, $x$ needs to be renamed into $x'$:
\begin{itemize}
\item $x$ will be the value of $x$ at the beginning of the path.
\item $x'$ will be the value of $x$ at the end of the path.
\end{itemize}
Indeed, there can be uses of $x$ along the path, and these uses refer to the
old value of $x$. 
\end{enumerate}

Finally, the $\rho$ formula is the following:

\begin{eqnarray*}
\rho = & \displaystyle\bigwedge_{p_i \notin P_R}& \left[ \left(b_i = \bigvee_{(p_h,p_i) \in E}
t_{h,i}\right) \wedge \left( \bigwedge_{(p_i,p_j)\in E} t_{i,j} = b_i \wedge
c(i,j)\right)
\right] \wedge \\
 & \displaystyle\bigwedge_{p_i \in P_R}& \left[ \left(b_i^d = \bigvee_{(p_h,p_i) \in E}
 t_{h,i}\right) \wedge \left( \bigwedge_{(p_i,p_j)\in E} t_{i,j} = b_i^s \wedge
 c(i,j)\right) \right] \wedge \\
 & \displaystyle\bigwedge_{x \in \Sigma}& assign(x)
\end{eqnarray*}

where $\Sigma$ is the set of the numerical SSA-variables of the program.

\begin{figure}[!h]
\begin{minipage}[c]{.49\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.5cm,
                    semithick,font=\footnotesize]

\tikzstyle{s}=[rectangle,fill=black!25,minimum size=13pt,inner sep=0pt]
\tikzstyle{t}=[rectangle,semithick,draw=black!75,
  			  minimum size=4mm]
\tikzstyle{PRs}=[rectangle,draw,fill=blue!15,minimum size=13pt,inner sep=0pt]
\tikzstyle{polyhedra}=[blue!25,opacity=0.5,pattern=north west lines,pattern
color=blue]
\tikzstyle{line}=[black,thick]

	\node[PRs] (n0) {$p_0$};
	\node[PRs] (n1) [below of=n0] {$\begin{array}{l}p_1 \\ x.1 =
	\Phi(x.0,x.1) \\ y.1 = \Phi(y.0,y.4)\end{array}$};
	\node[s] (n2) [below left of=n1,yshift=-0.5cm] {$p_2$};
	\node[s] (n3) [below right of=n1,yshift=-0.5cm] {$p_3$};
	\node[s] (n4) [below left of=n3,yshift=-0.2cm] {$\begin{array}{l}p_4\\ y.4 =
	\Phi(y.2,y.3)\end{array}$};
	\node[s] (n5) [below of=n4] {$p_5$};
	\node[s] (n6) [below of=n5] {$p_6$};
	\node[PRs] (n7) [left of=n6] {$p_7$};


  \path [transition] 
		(n0) edge              node {$\begin{array}{l} x.0 = 0 \\ y.0 =
		0\end{array}$} (n1);
  \path [transition] 
        (n1) edge			   node [left] {$x.1 \leq 50$} (n2);
  \path [transition] 
        (n1)  edge              node [right] {$x.1 \geq 51$} (n3);
  \path [transition] 
        (n2) edge              node [left] {$y.2 = y.1+1$} (n4);
  \path [transition] 
        (n3) edge			   node [right] {$y.3 = y.1-1$} (n4);
  \path [transition] 
        (n4) edge			   node {$y.4 \geq 0$} (n5);
  \path [transition] 
		(n4) edge  [out = 180, in=90] node [left] {$y.4 \leq -1$} (n7);
  \path [transition] 
        (n5) edge              node {$x.2 \leftarrow x.1+1$} (n6);
  \path [transition] 
        (n6) edge [out=0, in=0, distance=3.5cm] node {} (n1);
\end{tikzpicture}
(a) SSA form of the control flow graph seen in figure \ref{CFG}.
\end{minipage} 
$\Longrightarrow$ \hfill
\begin{minipage}[c]{.49\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.5cm,
                    semithick,font=\footnotesize]

\tikzstyle{s}=[rectangle,fill=black!25,minimum size=13pt,inner sep=0pt]
\tikzstyle{t}=[rectangle,semithick,draw=black!75,
  			  minimum size=4mm]
\tikzstyle{PRs}=[rectangle,draw,fill=blue!15,minimum size=13pt,inner sep=0pt]
\tikzstyle{polyhedra}=[blue!25,opacity=0.5,pattern=north west lines,pattern
color=blue]
\tikzstyle{line}=[black,thick]

	\node[PRs] (n0s) {$p_0^s$};
	\node[PRs] (n1s) [right of=n0s,xshift=1.3cm] {$p_1^s$};
	\node[PRs] (n7s) [right of=n1s,xshift=1.3cm] {$p_7^s$};
	\node[s] (n2) [below left of=n1s] {$p_2$};
	\node[s] (n3) [below right of=n1s] {$p_3$};
	\node[s] (n4) [below left of=n3,yshift=-0.2cm] {$\begin{array}{l}p_4\\ y.4 =
	\Phi(y.2,y.3)\end{array}$};
	\node[s] (n5) [below of=n4] {$p_5$};
	\node[s] (n6) [below of=n5,yshift=0.3cm] {$p_6$};
	\node[PRs] (n1d) [below of=n6] {$\begin{array}{l}p_1^d \\ x.1' =
	\Phi(x.0,x.1) \\ y.1' = \Phi(y.0,y.4)\end{array}$};
	\node[PRs] (n7) [right of=n1d,xshift=0.6cm] {$p_7^d$};
	\node[PRs] (n0d) [left of=n1d,xshift=-0.6cm] {$p_0^d$};


  \path [transition] 
		(n0s) edge   [out=-90]           node [left] {$\begin{array}{l} x.0 = 0 \\ y.0 =
		0\end{array}$} (n1d);
  \path [transition] 
        (n1s) edge			   node [left] {$x.1 \leq 50$} (n2);
  \path [transition] 
        (n1s)  edge              node [right] {$x.1 \geq 51$} (n3);
  \path [transition] 
        (n2) edge              node [left] {$y.2 = y.1+1$} (n4);
  \path [transition] 
        (n3) edge			   node [right] {$y.3 = y.1-1$} (n4);
  \path [transition] 
        (n4) edge			   node {$y.4 \geq 0$} (n5);
  \path [transition] 
		(n4) edge  [out = 0, in=90] node [left] {$y.4 \leq -1$} (n7);
  \path [transition] 
        (n5) edge              node {$x.2 \leftarrow x.1+1$} (n6);
  \path [transition] 
        (n6) edge				node {} (n1d);
\end{tikzpicture}

(b) control flow graph (a), such as it is represented by the SMT formula $\rho$.
Points in $P_R$ have been split into a ``source'' point and a ``destination''
point, and $\Phi$-variables associated to points in $P_R$ have been primed.
\end{minipage} 
\caption{Example (cont'd)}
\label{multigraphGopan}
\end{figure}

	\subsubsection{Expression of the reachability problem}
	\label{smtformula}
	The SMT-formula $\rho$ express the semantics of the program. We still need
	to create the
	formula expressing the reachability problem defined in \ref{reachability}.

	The abstract domain $D$ we use is those of convex polyhedra, so an abstract
	value $X \in D$ is simply a system of linear inequalities between the
	different SSA-variables of the program. Then, it is easy to encode the
	property $x \in X$ into an SMT-formula: one simply writes the conjunction of
	these inequalities, with the name of the variables in the vector $x$.

	To compute the reachability starting from point $p_i$, the formula given to
	the SMT-solver is:

	$$\rho \wedge b_i^s \wedge \bigwedge_{j\neq i,\ j\in P_R} (\neg b_j^s)
	\wedge x_i \in X_{p_i} \wedge \bigvee_{j/(p_i,p_j)\in E} (b_2^d \wedge \neg
	(x_j' \in X_{p_j}))$$

	where $x_i$ is the vector of the SSA-variables at the beginning of the path,
	and $x_j'$ is the vector of the SSA-variable at the end: in this second
	vector, $\Phi$-variables defined in $p_j$ are primed.

	\begin{itemize}
	\item we search a path starting in $p_i$: $b_i^s$ has to be \emph{true}, and
	all other source points are \emph{false}.
	\item the vector $x_i$ of the numerical variables at point $p_i$ is in our
	abstract value $X_{p_i}$
	\item we search a path arriving in a successor $p_j$ of $p_i$, such that the
	vector of the numerical variables $x_j'$ is not yet included in the current
	abstract value $X_{p_j}$ of $p_j$. $b_j^d$ is \emph{true}, and the
	conjunction of the inequalities given by $X_{p_j}$ is \emph{false}.
	\end{itemize}

	\subsection{Algorithm}
	
	The Path Focusing algorithm is described in Algorithm \ref{pathfocusingalgo}.
	We maintain a set $A$ of points in $P_R$ that need to be treated.
	We select iteratively one of these control points, and search for new focus
	paths starting from this point, until there is no more path to be treated.
	At the end of the analysis, some narrowing iterations can be performed in
	order to recover some precision.
\begin{algorithm}
\caption{Path Focusing}\label{pathfocusingalgo}
\begin{algorithmic}[1] 
\Procedure{pathfocusing}{$P$,$E$,$P_R$}
\ForAll {$p \in P_R$}
	\State Compute $Succ(p)$, the set of the successors of $p$ in the multigraph
\EndFor
\State $\rho \gets$ computeRho$(P,E)$
\State $A \gets \emptyset$
\ForAll {$p \in P_R / I_p \neq \emptyset$}
	\State $A \gets A \cup p$
\EndFor
\While{$A \neq \emptyset$}
	\State Select $p_i \in A$
	\State $A \gets A \setminus \{p_i\}$
	\While{true}
		\State $res \gets SmtSolve\left[\rho \wedge b_i^s \wedge
		\displaystyle\bigwedge_{\substack{j\neq i \\
		j\in P_R}} (\neg b_j^s) \wedge x_i \in X_{p_i} \wedge
		\bigvee_{\substack{j \\ p_j\in Succ(p_i)}} \left(b_2^d \wedge \neg (x'_j \in
		X_{p_j})\right)\right]$
		\If {$res = unsat$}
			\State \textbf{break}
		\EndIf
		\State Compute the focus path $e$ from $p_i$ to $p_j$
		\State $Y \gets \tau_e^\#(X_{p_i})$
		\If {$p_j \in P_W$}
			\State $X_{p_j} \gets X_{p_j} \widening (X_{p_j} \sqcup Y)$
		\Else
			\State $X_{p_j} \gets X_{p_j} \sqcup Y$
		\EndIf
		\State $A \gets A \cup \{p_j\}$
	\EndWhile
\EndWhile
\State Possibly perform some narrowing steps
\State Compute $\{X_{p_i},\ i \notin P_R\}$
\State \textbf{return} $\{X_{p_i},\ i \in P\}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

	\subsection {Precision of the analysis}

	One can refine the \emph{Path-focusing} algorithm by treating specially the
	self loops of the multigraph. Indeed, instead of simply apply the widening
	operator,  some narrowing steps could be performed to regain precision
	before focusing on another path. This relates to the ideas in
        \emph{Lookahead widening} \cite{GopanR06}.

	So, the algorithm has a special case if the path we focus on goes from $p_i$
	to itself: instead of computing $\tau_e^\#(X_{p_i})$, one compute
	$SelfLoop(\tau_e^\#,X_{p_i})$, defined in algorithm \ref{loopiteralgo}.

	The $SelfLoop$ procedure actually computes a widening operation, and
	computes a narrowing step in order to recover precision. In some cases,
	instead of performing widening/narrowing iterations, 
	acceleration techniques could be used 
	to find even more precise invariants \cite{GH06}.

	In order for this refinement to be precise, the widening
	operator needs to be delayed
	when we consider a self-loop for the first time. Then, our
	algorithm uses a set $U$ of paths that have already been treated. If the
	self-loop we focus on is not in $U$, we apply a simple union instead of
	widening. Widening will be applied next time to guarantee the convergence.

	When the self loop can be accelerated \cite{Gon07}, instead of doing a
	widening/narrowing sequence,  acceleration directly finds
	its transitive closure.

\begin{algorithm}
\caption{SelfLoop}
\label{loopiteralgo}
\begin{algorithmic}[1] 
\Procedure{SelfLoop}{$\tau_e^\#$,$X_{p_i}$}
	\State $Y \gets \tau_e^\#(X_{p_i})$
	\State $X' \gets X_{p_i}\widening (X_{p_i} \sqcup Y)$
	\State $Y \gets \tau_e^\#(X')$
	\State \textbf{return} $Y$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Path Focusing with special treatment for self loops}
\label{pathfocusingoptalgo}
\begin{algorithmic}[1] 
\Procedure{pathfocusing}{$P$,$E$,$P_R$}
\ForAll {$p \in P_R$}
	\State Compute $Succ(p)$, the set of the successors of $p$ in the multigraph
\EndFor
\State $\rho \gets$ computeRho$(P,E)$
\State $A \gets \emptyset$
\ForAll {$p \in P_R / I_p \neq \emptyset$}
	\State $A \gets A \cup p$
\EndFor
\While{$A \neq \emptyset$}
	\State Select $p_i \in A$
	\State $A \gets A \setminus \{p_i\}$
	\State $U \gets \emptyset$
	\While{true}
		\State $res \gets SmtSolve\left[\rho \wedge b_i^s \wedge
		\displaystyle\bigwedge_{\substack{j\neq i \\
		j\in P_R}} (\neg b_j^s) \wedge x_i \in X_{p_i} \wedge
		\bigvee_{\substack{j \\ p_j\in Succ(p_i)}} \left(b_2^d \wedge \neg (x'_j \in
		X_{p_j})\right)\right]$
		\If {$res = unsat$}
			\State \textbf{break}
		\EndIf
		\State Compute the focus path $e$ from $p_i$ to $p_j$
		\If{$p_i = p_j$}
			\State $Y \gets SelfLoop(\tau_e^\#,X_{p_i})$
		\Else
			\State $Y \gets \tau_e^\#(X_{p_i})$
		\EndIf
		\If {$(p_j \in P_W) \wedge (p_i \neq p_j \vee e \in U)$}
			\State $X_{p_j} \gets X_{p_j} \widening (X_{p_j} \sqcup Y)$
		\Else
			\State $X_{p_j} \gets X_{p_j} \sqcup Y$
			\State $U \gets U \cup \{e\}$
		\EndIf
		\State $A \gets A \cup \{p_j\}$
	\EndWhile
\EndWhile
\State Possibly perform some narrowing steps
\State Compute $\{X_{p_i},\ i \notin P_R\}$
\State \textbf{return} $\{X_{p_i},\ i \in P\}$
\EndProcedure
\end{algorithmic}
\end{algorithm}
	
	\subsection{Example}

	We apply the \emph{Path Focusing} technique to our running example from
	Figures \ref{runningexample}, \ref{multigraphtransformGopan} and
	\ref{multigraphGopan}.
	The control points in $P_R$ are $p_0$, $p_1$ and $p_7$. 
	The $\rho$ formula associated to this program is depicted in
	Figure \ref{rhoformula} (see appendices).
	One computes
	iteratively the associated abstract values $X_0$, $X_1$ and $X_7$.

\begin{itemize}
\item Step 0: Initially, $X_0 = \top, X_1 = \perp, X_7 = \perp$, and $A =
\{p_0\}$.
\item Step 1: We start in $p_0$. Is there a path starting in $p_0$, that arrives
in a state in $P_R$ and makes its abstract value grow? The SMT-solver answers
\emph{yes}, and gives the path $p_0 \rightarrow p_1$. We update $X_1$:
it is the polyhedron $x=y=0$. We update $A = \{p_1\}$. 
We do another SMT query: is there another path
starting in $p_0$ that makes an abstract value grow? The answer is no.
\item Step 2: We now work on $p_1$. Is there a path starting in $p_1$ that
arrives in a successor of $p_1$, and makes its abstract value grow? Answer is
yes, and the model given by the SMT-solver is the path $p_1 \rightarrow p_2
\rightarrow p_4 \rightarrow p_5 \rightarrow p_6 \rightarrow p_1$. Actually, this
is the first phase of the loop. 
The image of $x=y=0$ by this transition is $x=y=1$. The new $X_1$ is then $x=y
\wedge 0\leq x \leq 1$. The path is a self loop, but is seen for the first time,
so we do not apply widening yet. So, we redo an SMT-query, that gives us exactly
the same path. Then, we can do a widening/narrowing sequence. 
After widening, we have $x=y \wedge x \geq 0$, and narrowing gives $X_1 = (x=y)
\wedge (0 \leq x \leq 51)$.
\item Step 3: We still are in $p_1$: we ask for another focus path, and the
SMT-solver finds the path $p_1 \rightarrow p_3
\rightarrow p_4 \rightarrow p_5 \rightarrow p_6 \rightarrow p_1$. This is the
second phase of the loop, which is possible since $(x,y)=(51,51) \in X_1$.
Again, this is a self-loop, but we do not widen yet. The
image of $X_1$ by the transition is the single point $(52,50)$. $X_1$ is then
the convex hull of this point with the old $X_1$. A new SMT query gives the same
path, and we can now apply widening/narrowing. We obtain
$X_1 = (x \leq y) \wedge (102 - x - y \geq 0)$ after widening, and narrowing
gives $X_1 = (x \leq y) \wedge (102 - x - y \geq 0) \wedge y \geq 0$.
We can see that $X_1$ is the smallest polyhedron containing the possible values
for $(x,y)$ (see Figure \ref{result}.b).
\item Step 4: Again, we ask the SMT-solver for a new focus path, and it returns
$p_1 \rightarrow p_3 \rightarrow p_4 \rightarrow p_7$. The image of the
polyhedra $X_1$ after this path transformation is the single point $y=-1 \wedge
x = 102$. We can update $X_7 = {(102,-1)}$. Path focusing technique gives us the
precise result of this program. After that, the SMT-solver cannot find any new
path, so the analysis terminates.
\end{itemize}


%DM: en quoi tout ceci est de la transitive closure?
%DM: transitive closure c'est sur des relations i/o
%DM: note que tu pourrais faire des relations (summaries de boucles, etc.)
%DM: en gardant dans tes polyedres une copie des variables en tete
%DM: du bloc/fonction/truc

	\subsection{Disjunctive invariants}

	In this subsection, we propose an extension of the path focusing technique
	to compute disjunctive invariants, in order to improve precision of the
	analysis.

	\cite{GulwaniZ10} proposes a technique to compute transitive closure of a
	loop, i.e compute the invariants for a loop having its semantic
	expressed by a transition system. The definition of a transition system is
	the following:

	\begin{definition}
	A transition system for a control point $p$ is a DNF formula (i.e a
	disjunction of conjunctions), where each
	disjunct is the semantic of a path from $p$ to itself. It is of the form
	$$\bigvee_{1 \leq i \leq n} \tau_{p,i}$$ where $n$ is the number of
	paths, and $\tau_{p,i}$ is the semantic of the $i$-th path from $p$ to
	itself.
	\end{definition}

	The technique is aimed at computing a disjunctive invariant for this control
	point: 
	$$\displaystyle\bigvee_{1 \leq j \leq m} X_{p,j}$$
	where $X_{p,j}$ is a conjunction of linear inequalities, i.e a convex
	polyhedra.

	The principle of the method is to
	choose an integer $\delta \in \{1,..,m\}$, and a mapping function
	$\sigma: \{1,..,m\} \times \{1,..,n\} \mapsto \{1,..,m\}$.
	For each polyhedra of the disjunctive invariant, and for each path in the
	graph, the image of the polyhedra $X_{p,j}$ by the transition
	$\tau_{p,i}$ is joined with $X_{p,\sigma(j,i)}$.

\begin{algorithm}
\caption{Transitive closure}\label{gulwani}
\begin{algorithmic}[1] 
\Procedure{TransitiveClosure}{$\bigvee_{i=1}^n X_{p,i}$}
\ForAll {$j \in \{1,..,m\} \setminus \{\delta\}$}
	\State $X_{p,j} \gets \perp$
\EndFor
\State $X_{p,\delta} \gets Id$
\Repeat
	\For {$i \in \{1,..,n\}$ and $j \in \{1,..,m\}$}
		\State $X_{p,\sigma(j,i)} \gets X_{p,\sigma(j,i)} \sqcup
		\tau_{p,i}(X_{p,j})$
	\EndFor
\Until {no change in $\bigvee_{j=1}^m X_{p,j}$}
\EndProcedure
\end{algorithmic}
\end{algorithm}

There are heuristics to choose $m,\delta$ and $\sigma$ \cite[Section
5]{GulwaniZ10}.

This algorithm requires to enumerate all the paths and to compute their
semantics, which may result in an exponential blowup. In addition, the
\emph{for} loop at line $7$ iterates on all the $n \times m$ values of $(i,j)$:
some of the join operations may be useless, in the sense that the value of 
$X_{p,\sigma(j,i)}$ may not change. Here, the same technique as
Path Focusing is achievable to avoid these drawbacks:  SMT-solving is used
to find the paths $\tau_{p,i}$.

\begin{algorithm}[!h]
\caption{Transitive closure with implicit transition system}\label{gulwani2}
\begin{algorithmic}[1] 
\Procedure{TransitiveClosureImplicit}{$p$}
\ForAll {$j \in \{1,..,m\} \setminus \{\delta\}$}
	\State $X_{j} \gets \perp$
\EndFor
\State $X_{\delta} \gets Id$
\While {true}

		\State $res \gets SmtSolve\left[\rho \wedge b_k^s \wedge
		\bigvee_{j=1}^m (B_j \wedge x \in X_{j})
		\wedge b_k^d
		\wedge \neg \left(\bigvee_{j=1}^m x' \in X_{j}\right)\right]$

	\If {$res = unsat$}
		\State \textbf{break}
	\EndIf
	\State Compute $\tau_{p,i}$ from $res$ 
	\State Take $j \in \{ k | B_k = true\}$ 
	\State $X_{p,\sigma(j,i)} \gets X_{p,\sigma(j,i)} \sqcup
	\tau_{p,i}(X_{p,j})$
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

The new algorithm we propose is described in Algorithm \ref{gulwani2}.
A difference is that here, we do not know the number of paths. Then, the mapping
function $\sigma$ has to be defined on $\{1,..,m\} \times \N$. We could also
easily compute this number of paths when computing the $\rho$ formula.


	\subsection{Removing identity transitions}

	When computing iterations, some of the loop paths may not change the state
	of the variables, i.e the transition function associated to this path is the
	identity function. This happens in the case of expansive transition
	relations $\Phi$, defined by the property $X \subseteq \Phi(X)$.

	Considering the set of initial states $I$, and the transition function 
	$\tau$ mapping a state to its successor, we can define:

	$$\Phi(X) = \{ x'\ |\ \exists x \in X, x' = \tau(x)\} \cup I$$

	$\Phi$ is the function we classically use to find an inductive invariant
	$X$, satisfying the property $\Phi(X) \subseteq X$. To improve the analysis,
	we propose to compute this invariant using another function $\Psi$, by
	removing the transitions that are actually the identity. Indeed, these
	transitions make no change to the set $X$.
	The $\Psi$ function could be expressed as follows:

	$$\Psi(X) = \{ x'\ |\ \exists x \in X, x' = \tau(x) \wedge x' \neq x\}
	\cup I$$

	It is easy to prove that $\Psi(X) \subseteq X \Leftrightarrow \Phi(X)
	\subseteq(X)$, so we can use $\Psi$ instead of $\Phi$ to compute our
	invariant.

	In the case of path focusing algorithm, we simply conjunct our formula
	(see \ref{smtformula}) with
	$(i \neq j) \vee (x'_j \neq x_i)$, such that the SMT-solving only proposes
	paths that are not the identity. Actually, it never focuses on such paths
	during the ascending sequence, but during narrowing iterations that occur 
	at the end of the algorithm.

	Ignoring these identity transitions makes the narrowing sequence recover
	more precision.
	Indeed, narrowing sequence updates the invariant $X$ with $\Phi(X)$, which
	is still an invariant, while precision is recovered, meaning that $\Phi(X)
	\subset X$. In the case of an expansive function, where $X \subseteq
	\Phi(X)$, we never have $\Phi(X) \subset X$, so narrowing iterations are
	useless.

	

	\section{Efficiency comparison: example}

In this subsection, we propose an example showing that \emph{Path Focusing}
technique performs better than \emph{Lookahead Widening} in the case of loops
with intermediate control-flow merges.

We consider the program depicted in Figure \ref{ex9}, page \pageref{ex9}.
Here, we would like to show that the returned value $r$ is zero.

\begin{figure}[!h]
\begin{minipage}[c]{.49\linewidth}
\begin{C}
x = 0;
i = 0;
r = 0;
while (i < 100) {
	if (i < 50)
		x = -1;
	else
		x = 1;

	if (x == 0) r++;
	i++;
}
return r;
\end{C}
\end{minipage}
\begin{minipage}[c]{.49\linewidth}
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.5cm,
                    semithick,font=\footnotesize]

	\node[state] (n0) {$p_0$};
	\node[state] (n1) [below of=n0] {$p_1$};
	\node[state] (n2) [below of=n1] {$p_2$};
	\node[state] (n3) [below left of=n2] {$p_3$};
	\node[state] (n4) [below right of=n2] {$p_4$};
	\node[state] (n5) [below right of=n3] {$p_5$};
	\node[state] (n6) [below left of=n5] {$p_6$};
	\node[state] (n7) [below right of=n5] {$p_7$};
	\node[state] (n8) [below left of=n7] {$p_8$};
	\node[state] (n9) [left of=n1] {$p_9$};


  \path [transition] 
		(n0) edge              node {$x,i,r \leftarrow 0$} (n1);
  \path [transition] 
		(n1) edge              node {$i < 100$} (n2);
  \path [transition] 
		(n1) edge              node {$i \geq 100$} (n9);
  \path [transition] 
        (n2) edge			   node [left] {$i < 50$} (n3);
  \path [transition] 
        (n2)  edge              node [right] {$i \geq 50$} (n4);
  \path [transition] 
        (n3) edge              node [left] {$x \leftarrow -1$} (n5);
  \path [transition] 
        (n4) edge			   node [right] {$x \leftarrow 1$} (n5);
  \path [transition] 
        (n5) edge			   node [left] {$x = 0$} (n6);
  \path [transition] 
        (n5) edge			   node [right] {$x \neq 0$} (n7);
  \path [transition] 
        (n6) edge              node [left] {$r \gets r+1$} (n8);
  \path [transition] 
        (n7) edge              node {} (n8);
  \path [transition] 
        (n8) edge [out=0, in=0, distance=3.5cm] node [right] {$i \gets i+1$} (n1);

\end{tikzpicture}
\end{minipage}
\caption{Example of program. $p_5$ is a control-flow merge point, which is in
the middle of the containing loop.}
\label{ex9}
\end{figure}

\paragraph{Lookahead Widening} 
The analysis begins with $p_1: x=i=r=0$. Then, the path $p_1 \rightarrow p_2
\rightarrow p_3 \rightarrow p_5 \rightarrow p_7 \rightarrow p_1$ is the only one
possible. The technique is then to stabilise the iterations over this subgraph,
removing $p_4$ and $p_6$ for a while. After stabilisation and narrowing phases,
we obtain $ 0 \leq i \leq 50 \wedge r=0 \wedge -1 \leq x \leq 0$ at
control point $p_1$, and 
$ 0 \leq i \leq 49 \wedge r=0 \wedge x=-1$ at point $p_5$.

Then, point $p_4$ becomes reachable. We continue the iterations and have to do
a convex hull of polyhedra at point $p_5$, because of the two possible incoming
transitions.
We obtain the polyhedron
$ 0 \leq i \leq 50 \wedge r=0 \wedge -1 \leq x \leq 1$.
Point $p_6$ now becomes reachable, since $x=0$ is inside our polyhedron.
Finally, the analysis terminates after some steps and finds $0 \leq r \leq i$.
\emph{Lookahead Widening} is not able to prove that $r = 0$ at the end of the
function.

\paragraph{Path Focusing} 
The analysis of the loop starts with 
$p_1: x=i=r=0$. Then, the SMT-solver discovers the path $p_1 \rightarrow p_2
\rightarrow p_3 \rightarrow p_5 \rightarrow p_7 \rightarrow p_1$. We do a
widening/narrowing sequence and we find 
$ 0 \leq i \leq 50 \wedge r=0 \wedge -1 \leq x \leq 0$ at $p_1$. The SMT-solver
gives another path: 
$p_1 \rightarrow p_2
\rightarrow p_4 \rightarrow p_5 \rightarrow p_7 \rightarrow p_1$. After
analysing this path, we obtain 
$ 0 \leq i \leq 100 \wedge r=0 \wedge x=0$. Analysis terminates since the
SMT-solver gives $unsat$ answers. Here, We never focused on paths going through
point $p_6$, so our analysis gives us the invariant $x=0$ at the end of the
program. Indeed, there is no feasible paths going through $p_6$, but
\emph{Lookahead Widening} do not know it because of the convex hull at point
$p_5$.





\FloatBarrier
\chapter{Implementation}\label{implementationpart}

\emph{Lookahead Widening} and \emph{Path Focusing}
techniques have been implemented into a small analyser, so that we can compare
the precision of their results. In this part, we explain some details about
these implementations.

 \section{Infrastructure}
The analyser is based on the \emph{Low Level Virtual Machine} (LLVM)
\cite{LLVM:CGO04}, which is a compilation infrastructure used for instance by
the \emph{clang} compiler.

\subsection{LLVM internal representation}
% We need layers to draw the block diagram
\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

% Define a few styles and constants
\tikzstyle{sensor}=[draw, fill=blue!20, text width=5em, 
    text centered, minimum height=2.5em]
\tikzstyle{ann} = [above, text width=5em]
\tikzstyle{IR} = [sensor, text width=6em, fill=red!20, 
    minimum height=12em, rounded corners]
\def\leftdist{2.3}
\def\rightdist{5.0}
\def\edgedist{2.5}

\begin{figure}[!h]
\centering
\begin{tikzpicture}
    \node (IR) [IR] {\small Internal\\Representation\\ (IR)};
    % Note the use of \path instead of \node at ... below. 
    \path (IR.130)+(-\leftdist,0) node (c) [sensor] {C};
    %\path (IR.-150)+(-\leftdist,0) node (cpp) [sensor] {C++};
	\node [sensor] (cpp) [below of=c, yshift=-0.3cm] {C++};
	\node  (lang) [below of=cpp] {$\vdots$};
    
    \path (IR.130)+(+\rightdist,0) node (x8664) [sensor] {Binary\\ x86\_64};
	\node [sensor] (i686) [below of=x8664, yshift=-0.3cm] {Binary\\ i686};
	\node  (Out) [below of=i686] {$\vdots$};
	
	\path [draw, ->] (cpp) -- (IR);
	\path [draw, ->] (c) -- (IR);
	\path [draw, ->] (lang) -- (IR);

	\path [draw, ->] (IR) -- (x8664);
	\path [draw, ->] (IR) -- (i686);
	\path [draw, ->] (IR) -- (Out);
    
	% We could simply have written (gyros) .. (naveq.140). However, it's
    % best to avoid hard coding coordinates
    \node (Input) [below of=lang] {Input};
    \node (Output) [below of=Out] {Output};
    \path (IR.south west)+(-0.6,-0.4) node (Frontend) {Frontend};
    \path (IR.south east)+(+0.6,-0.4) node (Backend) {Backend};
    
    % Now it's time to draw the colored IMU and INS rectangles.
    % To draw them behind the blocks we use pgf layers. This way we  
    % can use the above block coordinates to place the backgrounds   
    \begin{pgfonlayer}{background}
        % Compute a few helper coordinates
        \path (c.west |- IR.north)+(-0.5,0.3) node (a) {};
        \path (Frontend.south -| x8664.east)+(+0.5,-0.2) node (b) {};
        \path[fill=yellow!20,rounded corners, draw=black!50, dashed]
            (a) rectangle (b);
        \path (c.north west)+(-0.2,0.2) node (a) {};
        \path (Input.south -| c.east)+(+0.2,-0.2) node (b) {};
        \path[fill=blue!10,rounded corners, draw=black!50, dashed]
            (a) rectangle (b);
        \path (x8664.north west)+(-0.2,0.2) node (a) {};
        \path (Output.south -| x8664.east)+(+0.2,-0.2) node (b) {};
        \path[fill=blue!10,rounded corners, draw=black!50, dashed]
            (a) rectangle (b);
    \end{pgfonlayer}
\end{tikzpicture}
\end{figure}
\FloatBarrier

The advantage of using such an infrastructure is that the analyser can check
programs written in various languages: C, C++, \dots, without needing to write
a specific frontend for each of them. Here, the analyser directly works on the
internal representation (IR), which is a graph representation of
the program. The control flow graph can easily be extracted from
this representation.

Our analyser takes as parameter the LLVM internal representation of a program,
and returns linear relations between the numerical variables at each control
point of this program. It first applies some optimisation passes over the IR,
and then computes the linear relations by abstract interpretation.

\begin{figure}[!h]
\begin{minipage}[c]{.35\linewidth}
{\small
\begin{C}
int main() {
   int x = 0;
   int y = 0;

   while (1) {
      if (x <= 50) y++;
      else y--;

      if (y < 0) break;
      x++;
   }
}
\end{C}
}
\end{minipage}
\begin{minipage}[c]{.69\linewidth}
%\includegraphics[width=8.5cm]{"images/cfg_gopan"}

{\tiny
% \begin{tikzpicture}[anchor=mid,>=latex',line join=bevel,]
\begin{tikzpicture}[>=latex',line join=bevel,scale=0.5]
  \pgfsetlinewidth{1bp}
%%
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (273bp,13bp) node {CFG for 'main' function};
\end{scope}
  \pgfsetcolor{black}
  % Edge: Node0x9828da8 -> Node0x9828dd8
  \draw [->] (356.55bp,400.82bp) .. controls (333.72bp,390.36bp) and (308.41bp,378.75bp)  .. (274.21bp,363.07bp);
  % Edge: Node0x9828b18 -> Node0x9828d48
  \draw [->] (310bp,694.72bp) .. controls (310bp,686.41bp) and (310bp,677bp)  .. (310bp,657.09bp);
  % Edge: Node0x9828dd8 -> Node0x9828e08
  \draw [->] (70bp,241bp) .. controls (70bp,229.11bp) and (70bp,216.19bp)  .. (70bp,194.35bp);
  % Edge: Node0x9828d48 -> Node0x9828da8
  \draw [->] (456bp,530bp) .. controls (475.15bp,530bp) and (473.05bp,509.87bp)  .. (461.87bp,479.21bp);
  % Edge: Node0x9828e08 -> Node0x9828e68
  \draw [->] (70bp,133.91bp) .. controls (70bp,122.63bp) and (70bp,109.61bp)  .. (70bp,87.235bp);
  % Edge: Node0x9828d78 -> Node0x9828dd8
  \draw [->] (155.32bp,400.82bp) .. controls (154.06bp,392.13bp) and (152.69bp,382.65bp)  .. (149.87bp,363.2bp);
  % Edge: Node0x9828d48 -> Node0x9828d78
  \draw [->] (164bp,530bp) .. controls (145.24bp,530bp) and (143.41bp,510.23bp)  .. (148.69bp,479.21bp);
  % Edge: Node0x9828e38 -> Node0x9828d48
  \draw [->] (285.99bp,203.34bp) .. controls (287.87bp,215.1bp) and (289.73bp,228.04bp)  .. (291bp,240bp) .. controls (300.66bp,331.07bp) and (305.54bp,436.13bp)  .. (308.25bp,516.72bp);
  % Edge: Node0x9828dd8 -> Node0x9828e38
  %\draw [->] (284bp,254bp) .. controls (293.39bp,254bp) and (292.88bp,234.23bp)  .. (287.99bp,203.21bp);
  \draw [->] (210bp,240bp) -- (240.99bp,203.21bp);
  % Node: Node0x9828d48
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (165bp,517bp) -- (165bp,657bp) -- (455bp,657bp) -- (455bp,517bp) -- cycle;
  \draw (165bp,543bp) -- (455bp,543bp);
  \draw (310bp,517bp) -- (310bp,543bp);
  \draw (173bp,639bp) node[right] {\%1:};
  \draw (173bp,605bp) node[right] { \%x.0 = phi i32 [ 0, \%0 ], [ \%11, \%10 ]};
  \draw (173bp,587bp) node[right] { \%y.1 = phi i32 [ 0, \%0 ], [ \%y.0, \%10 ]};
  \draw (173bp,569bp) node[right] { \%2 = icmp sle i32 \%x.0, 50};
  \draw (173bp,551bp) node[right] { br i1 \%2, label \%3, label \%5};
  \draw (238bp,525bp) node {T};
  \draw (383bp,525bp) node {F};
\end{scope}
  % Node: Node0x9828b18
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (261bp,695bp) -- (261bp,755bp) -- (360bp,755bp) -- (360bp,695bp) -- cycle;
  \draw (269bp,737bp) node[right] {\%0:};
  \draw (269bp,703bp) node[right] { br label \%1};
\end{scope}
  % Node: Node0x9828e68
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (30bp,27bp) -- (30bp,87bp) -- (111bp,87bp) -- (111bp,27bp) -- cycle;
  \draw (38bp,69bp) node[right] {\%12:};
  \draw (38bp,35bp) node[right] { ret i32 0};
\end{scope}
  % Node: Node0x9828e38
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (172bp,125bp) -- (172bp,203bp) -- (387bp,203bp) -- (387bp,125bp) -- cycle;
  \draw (180bp,185bp) node[right] {\%10:};
  \draw (180bp,151bp) node[right] { \%11 = add nsw i32 \%x.0, 1};
  \draw (180bp,133bp) node[right] { br label \%1};
\end{scope}
  % Node: Node0x9828da8
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (338bp,401bp) -- (338bp,479bp) -- (547bp,479bp) -- (547bp,401bp) -- cycle;
  \draw (346bp,461bp) node[right] {\%5:};
  \draw (346bp,427bp) node[right] { \%6 = add nsw i32 \%y.1, -1};
  \draw (346bp,409bp) node[right] { br label \%7};
\end{scope}
  % Node: Node0x9828d78
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (59bp,401bp) -- (59bp,479bp) -- (263bp,479bp) -- (263bp,401bp) -- cycle;
  \draw (67bp,461bp) node[right] {\%3:};
  \draw (67bp,427bp) node[right] { \%4 = add nsw i32 \%y.1, 1};
  \draw (67bp,409bp) node[right] { br label \%7};
\end{scope}
  % Node: Node0x9828dd8
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (-1bp,241bp) -- (-1bp,363bp) -- (283bp,363bp) -- (283bp,241bp) -- cycle;
  \draw (-1bp,267bp) -- (283bp,267bp);
  \draw (142bp,241bp) -- (142bp,267bp);
  \draw (8bp,345bp) node[right] {\%7:};
  \draw (8bp,311bp) node[right] { \%y.0 = phi i32 [ \%4, \%3 ], [ \%6, \%5 ]};
  \draw (8bp,293bp) node[right] { \%8 = icmp slt i32 \%y.0, 0};
  \draw (8bp,275bp) node[right] { br i1 \%8, label \%9, label \%10};
  \draw (71bp,249bp) node {T};
  \draw (212bp,249bp) node {F};
\end{scope}
  % Node: Node0x9828e08
\begin{scope}
  \definecolor{strokecol}{rgb}{0.0,0.0,0.0};
  \pgfsetstrokecolor{strokecol}
  \draw (16bp,134bp) -- (16bp,194bp) -- (124bp,194bp) -- (124bp,134bp) -- cycle;
  \draw (24bp,176bp) node[right] {\%9:};
  \draw (24bp,142bp) node[right] { br label \%12};
\end{scope}
%
\end{tikzpicture}
}


\end{minipage}
\caption{Our running example and its internal representation in SSA form}
\label{IR}
\end{figure}
\FloatBarrier

As we see if Figure \ref{IR}, LLVM IR is slightly different from
our definition of control flow graph: it uses the notion of \emph{BasicBlock}.
A \emph{BasicBlock} is a sequence of instructions that are necessarily executed
one after the others, meaning that if the first intruction of a BasicBlock is
executed, then the rest of the instructions are necessarily executed exactly
once, in order.

In our case, a control point will be a BasicBlock of the program.

\subsection{Transformation passes}

LLVM internal representation can be applied transformation passes that modifies
parts of it. These passes are mostly used for optimisation purpose. In our
analyser, we apply some already existing passes before running our 
abstract interpretation pass. Among the passes we run, we could cite:
\begin{itemize}
\item the \emph{PromoteMemoryToRegister} Pass, that transforms the internal
representation by promoting the memory variables to Static Single Assignment
(SSA) registers. This pass transform the control flow graph such that all the
variables are in SSA form, and removes most of the \emph{Load/Store} operations
into memory. It is useful since our analyser does not have a memory model, and
then loses lots of precision in the case of \emph{Load/Store} instructions.
\item the \emph{LoopSimplify} and \emph{LoopInfo} Passes, that transform all loops into a canonical
format, and compute some information related to loops (for instance, the set of
BasicBlocks that are parts of the loop, etc.).
\item the \emph{LowerSwitch} Pass, that transform a switch instruction into its
corresponding \emph{if-then-else} instructions. After running this pass, there
is no more \emph{Switch} instruction in the control flow graph, so the
implementation of the static analysis is easier.
\end{itemize}


\subsection{Drawbacks}

During the implementation, we encountered problems due to the use of the LLVM
internal representation. Indeed, this format is not provided for static
analysis, but for code generation. Then, some informations we need for a precise
static analysis are lacking.

This is the case for the distinction between \emph{signed} and \emph{unsigned}
integers, which is nonexistent in the representation, since the compiler does
not
need this information to generate code. Yet, for static analysis, 
this distinction is required to improve precision:
for instance, if $n$ is unsigned, the constraint $n \geq 0$ could be added in
	our abstract value at the beginning of the analysis.
	This lack of precision may be limited by using disjunctive invariants: one
	could attach two polyhedra to the control point: the first one with the
	constraint $n \geq 0$, and the second one with $n < 0$.


Another example of information that was missing is the set of live variables.
Indeed, in LLVM, live variables computation is processed during the register
allocation. Then, the data structure we work on does not have live variables
informations yet. To solve this problem, we coded our own pass, that is aimed at
computing these live variables after the transformation in SSA form.

 \section{Abstract domain representation}

	The analyser is implemented using the APRON library \cite{JM09}, which
	is a common interface to libraries implementing all the features
	for several abstract domains, such as convex polyhedra (NewPolka), 
	octagons (OCT), intervals (BOX).
	In our case, we used the convex polyhedra library, but we could switch
	to octagons or intervals easily.

	\subsection{Attachment to LLVM Internal Representation}

	We attach only one abstract value to each BasicBlock of the IR. Indeed,
	there would be a huge memory consumption if we would attach a polyhedron
	after each instruction. A BasicBlock begins with all its $\Phi$-variables,
	and ends with the other instructions. We choose to attach our abstract value
	just after the $\Phi$-variables assignments. In this way, the
	$\Phi$-variables of the associated BasicBlock will be part of the dimensions
	of the polyhedron.


\begin{figure}[!h]
\centering
\begin{tikzpicture}
	\tikzstyle{bb} = [text width=6em, minimum height=12em]
	\tikzstyle{part}=[draw, fill=blue!10, text width=5em, 
    text centered, minimum height=2.5em, rounded corners, dashed]
	\tikzstyle{abstract}=[draw, circle, fill=red!20, text width=5em, 
    text centered, minimum height=2em,
	decorate,
    decoration={random steps,
		segment length=6pt,
		amplitude=4pt}
	]
    \node (bb) [bb]  {};
    \node (Phi) [part] [above of=bb] {\small $\Phi$-variables};
    \node (middle)  [below of=Phi] {};
    \node (inst) [part] [below of=bb] {\small Instructions};
	\node [abstract] (A) [left of=bb, xshift=-2cm] {Abstract \\ value};
	
	\path [draw, ->] (A) -- (middle);
	\path [draw, ->] (Phi) -- (inst);

    \path (inst.south)+(0,-1) node (label) {BasicBlock};
    
    \begin{pgfonlayer}{background}
        % Compute a few helper coordinates
        \path (Phi.north east)+(0.2,0.2) node (a) {};
        \path (inst.south west)+(-0.2,-0.2) node (b) {};
        \path[fill=yellow!20,rounded corners, draw=black!50, dashed]
            (a) rectangle (b);

        %\path (Phi.north west)+(-0.2,0.2) node (a) {};
        %\path (Phi.south east)+(+0.2,-0.2) node (b) {};
        %\path[fill=blue!10,rounded corners, draw=black!50, dashed]
        %    (a) rectangle (b);
        %\path (inst.north west)+(-0.2,0.2) node (a) {};
        %\path (inst.south east)+(+0.2,-0.2) node (b) {};
        %\path[fill=blue!10,rounded corners, draw=black!50, dashed]
        %    (a) rectangle (b);
       % \path (IR.north west)+(-0.2,0.2) node (a) {};
       % \path (IR.south -| IR.east)+(+0.2,-0.2) node (b) {};
       % \path[fill=blue!10,rounded corners, draw=black!50, dashed]
       %     (a) rectangle (b);
    \end{pgfonlayer}
\end{tikzpicture}
\end{figure}
\FloatBarrier

	\subsection{Dimensions of the abstract values}
	
	In our implementation, we tried to reduce as much as possible the dimensions
	of the abstract values at each program point. Indeed, there is no need to
	consider the whole set of the program numerical variables at each point $p$,
	since lots of these variables are not \emph{live} in $p$. 
	The definition of a \emph{live} variable is the following:

	\begin{definition}[Liveness]
	A variable is \emph{live} at the control point $p$ iff:
	\begin{itemize}
	\item its value is available at $p$, meaning that there is a path from the
	point defining the variable to $p$.
	\item its value might be used in the future, meaning that there exist a path
	starting in $p$, that arrives in a point using the variable.
	\end{itemize}
	\end{definition}

	LLVM internal representation allows to find the control point where
	a variable is defined and used, thanks to def-use chains: we can
	easily get the set of points where a variable is used, and we directly have
	a pointer to its definition.
	With all these informations, we implemented an LLVM pass that computes 
	the set of live variables in SSA, using the liveness check algorithm
	described in \cite[section 3.3]{Boi10}.

	
	At a program point $p$, the dimensions of the associated abstract value could
	only be the numerical variables that are live at $p$. This is
	not exactly the case in our implementation, because of another 
	optimisation: we only consider
	variables that are not a linear combination of other variables.

	For instance, assume that $x,y,z$ are numerical variables of a program,
	$x$ is defined as $x = y+z$, and $x,y,z$ are live at point $p$. Instead of having
	$x$ as a dimension for $X_p$, we only have $y$ and $z$. All the properties
	for $x$ can be directly extracted from $X_p$ and the information $x=y+z$.
	This is an optimisation in the sense that there is redundant information in
	the abstract value if both $x,y$ and $z$ are dimensions of $X_p$.

	Then, liveness definition can be adapted in our case:

	\begin{definition}[Liveness by linearity]
	A variable $v$ is \emph{live by linearity} at the control point $p$ iff:
	\begin{itemize}
	\item 
	its value is available at $p$, meaning that there is a path from the
	point defining the variable to $p$,
	\item one of these conditions holds:
		\begin{itemize}
		\item $v$ is live in $p$.
		\item There is a variable $v'$, defined as a linear combination of other
		variables $v_1, v_2, \dots, v_n$, so that $\exists i \in \{1,\dots,n\}, v = v_i$,
		and $v'$ is live by linearity in $p$.
		\end{itemize}
	\end{itemize}
	\end{definition}

	Finally, a variable is a dimension of $X_p$ iff it is live by linearity and
	it is not defined as a linear combination of program variables.


	There is a special case for $\Phi$-variables: in some cases, a
	$\Phi$-variable can be considered as a linear combination of program
	variables, when only a single incoming value is possible. This is the case
	when all but one polyhedra associated to a predecessor are at bottom.
	For instance, let's say point $p$ has $p_1, p_2, \dots, p_n$ as ordered 
	predecessors. At point $p$, we have $x = \Phi(x_1, x_2,\dots,x_n)$.
	If $\forall i \in \{2,\dots,n\}, X_i = \perp$, and $X_1 \neq \perp$, then we
	can use the linear relation $x = x_1$ instead of the $\Phi$ function. In
	practical cases, this is a way to reduce the size of the abstract values.


\subsection{Diseq comparisons}

The set of elements $x$ satisfying $x \neq N$ is not convex: it is the union of
two intervals: $]-\infty, N[\  \cup\  ]N,+\infty[$. Since we use convex polyhedra to
represent the set of possible states of our program, we loose information when
the analysis comes across a \emph{diseq} operation.
One classical approach would be to compute a disjunctive invariant, by attaching
two different polyhedron to the BasicBlock. However, we preferred the following
technique: we transform all the operations of the form $x \neq y$ into
$x < y \vee x > y$, meaning that we separate the cases \emph{less than} and
\emph{greater than} into two distinct paths.

\begin{minipage}[c]{.29\linewidth}
\begin{C}
if (x != y) {
	...
}
\end{C}
\end{minipage} $\Rightarrow$
\begin{minipage}[c]{.69\linewidth}
\centering
\begin{C}
	if (x > y) {
	} else if (x < y) {
	} else {
		...
	}
\end{C}
\end{minipage}

To do so, we could implement an LLVM pass that transform the internal
representation according to this principle. However, this pass has not been
implemented in our analyser, and this transformation has to be done manually.

\section{Unrolling loops}

In some cases, the number of iterations inside a loop during execution 
may be equal to zero. This happens if the condition of the \emph{while}
statement is false at the first time the head of loop is reached.

In our analyser, this kind of loops gives imprecise results. In this section, we
propose to unroll loops once in order to avoid it.
This behaviour can happen in very simple programs, such as the one
depicted in Figure \ref{loop}. Indeed, in the case of $n \leq 0$, the condition
$i < n$ is always false.

\begin{figure}[!h]
\begin{minipage}[c]{.29\linewidth}
\begin{C}
i=0;
while (i < n)
	i++;
\end{C}
\end{minipage}
\begin{minipage}[c]{.69\linewidth}
\centering
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.3cm,
                    semithick,font=\footnotesize]

	\node[state] (n0) {$p_0$};
	\node[state] (n1) [below of=n0] {$p_1$};
	\node[state] (n3) [below right of=n1] {$p_3$};
	\node[state] (n4) [below of=n3] {$p_4$};
	\node[state] (n2) [left of=n4,xshift=-1cm] {$p_f$};

  \path [transition] 
		(n0) edge              node {$i \gets 0$} (n1);
  \path [transition] 
        (n1) edge [out=180,in=90]	node [left] {$i \geq n$} (n2);
  \path [transition] 
        (n1) edge			   node [right] {$i < n$} (n3);
  \path [transition] 
		(n3) edge              node {$i \gets i+1$} (n4);
  \path [transition] 
        (n4) edge [out=0, in=0, distance=2.5cm] node {} (n1);

\end{tikzpicture}
\end{minipage}
\caption{If $n \leq 0$, there is no loop iterations.}
\label{loop}
\end{figure}

In this example, our program behaves as follows:
\begin{itemize}
\item At point $p_1$, we first have the polyhedron $i=0$, where $n$ in
unconstrained.
\item The image of this polyhedron after the loop transition is $i \leq n \wedge
i=1$. After a convex hull, we obtain for $p_1$ $0 \leq i \leq 1$.
\item Again, we
compute the image of this polyhedron by the transition, $1 \leq i \leq 2 \wedge
i \leq n$, and after widening we
obtain at $p_1$ the polyhedron $0 \leq i$.
\item Finally, at point $p_f$, we have the polyhedron $0 \leq i \wedge i \geq
n$.
\end{itemize}

Now, after unrolling the loop once, the program is the one in Figure
\ref{loopunroll}. The analysis gives:
\begin{itemize}
\item At point $p_1$, we have $i=0$, then we directly have at point $p_f$ the
polyhedron $i=0 \wedge n \leq 0$.
\item At point $p_4$, we first have $i=1 \wedge n \geq 1$.
\item the image of the polyhedron after the loop transition is $2 \leq n \wedge
i=2$, which gives after a convex hull $ 1 \leq i \leq 2 \wedge i \leq n$.
\item After one iteration and an application of widening, we find at $p_4$ the
polyhedron $1 \leq i \leq n$.
\item Then, at the exit point $p_f'$ of the loop, we have the polyhedron
$i = n \wedge i \geq 1$.
\end{itemize}

\begin{figure}[!h]
\begin{minipage}[c]{.29\linewidth}
\begin{C}
i=0;
if (i < n) {
	i++;
	while (i < n)
		i++;
}
\end{C}
\end{minipage}
\begin{minipage}[c]{.69\linewidth}
\centering
\begin{tikzpicture}[->,>=stealth',auto,node distance=1.3cm,
                    semithick,font=\footnotesize]

	\node[state] (n0) {$p_0$};
	\node[state] (n1) [below of=n0] {$p_1$};
	\node[state] (n3) [below right of=n1] {$p_3$};
	\node[state] (n4) [below of=n3] {$p_4$};
	\node[state] (n2) [left of=n4,xshift=-1cm] {$p_f$};
	\node[state] (n22) [below of=n2,yshift=0.5cm] {$p_f'$};
	\node[state] (n5) [below of=n4] {$p_5$};
	\node[state] (n6) [below of=n5] {$p_6$};

  \path [transition] 
		(n0) edge              node {$i \gets 0$} (n1);
  \path [transition] 
        (n1) edge [out=180,in=90]	node [left] {$i \geq n$} (n2);
  \path [transition] 
        (n1) edge			   node [right] {$i < n$} (n3);
  \path [transition] 
		(n3) edge              node {$i \gets i+1$} (n4);
  \path [transition] 
		(n4) edge              node {$i \geq n$} (n22);
  \path [transition] 
		(n4) edge              node {$i < n$} (n5);
  \path [transition] 
		(n5) edge              node [right] {$i \gets i+1$} (n6);
  \path [transition] 
        (n6) edge [out=0, in=0, distance=2.5cm] node {} (n4);

\end{tikzpicture}
\end{minipage}
\caption{Program of Figure \ref{loop} after unrolling the loop once.}
\label{loopunroll}
\end{figure}


The convex hull of the polyhedron from $p_f$ with the one from $p_f'$ also gives
$0 \leq i \wedge i \geq n$. Then, unrolling the loop does not give a better
solution, since
$p_f$ and $p_f'$ may be the same control point.

However, our technique does a convex hull only if this exit point is in $P_R$. 
If not, we consider independently the paths starting from $p_4$ and the ones
starting from $p_1$, hence the better precision. Indeed, this comes to computing
a disjunctive invariant for the loop, by distinguishing the case where the
number of iterations is zero. 

In our analyser, we unroll every loops once, by using LLVM optimisation
passes such as \emph{loop-unroll}, \emph{loop-rotate} or \emph{loop-simplify}.


	\section{SMT-solving}

	\emph{Path focusing} technique requires to decide the satisfiability of some
	SMT formula, and to extract a model when the formula is satisfiable, i.e an
	assignment of the variables so that the formula is \emph{true}. For doing
	this, our implementation has an interface with Microsoft Z3 \cite{MouraB08},
	and Yices \cite{DutertreM06}. One can easily switch from one to another with
	an argument we give as parameter to the analyser. In this way, we can
	compare the efficiency of both SMT-solvers.

	\section{Limitations}

	Our analyser could be extended in many ways. Indeed, it is intra-procedural,
	meaning that it does not consider that a variable may change after a
	function call. In addition, the return value of a function call is
	considered unconstrained. This limitation can be addressed by simply
	inlining the function call, provided the function is not recursive.
	There have been research to find efficient interprocedural analysis
	techniques \cite{Bourdoncle90,Bou92,jeannet09b}.

	Additionally, our analyser has no memory model:
\begin{itemize}
\item \emph{Store} instructions, that store a value in the memory, has no effect
in the analysis.
\item \emph{Load} instructions, that get a value $v$ in the memory and assign it
to a variable $x$, does not provide properties about the value $v$. Then, our
analyser considers $x$ can take all values of its type.
\end{itemize}
In the case of local variables, the transformation of the internal
representation into SSA form removes the \emph{Load/Store} instructions.
The use of global variables instead of local ones will induce huge
loss of precision, since there will still be \emph{Load/Store} instructions in
the IA.

Additionally, some optimisation in the code could be proposed in order to
reduce time and/or memory complexity. For instance, paths that have already been
computed are until now stored in a tree. An optimisation could be to store them
in a Binary Decision Diagram, in order to reduce significantly the memory
consumption when there is a huge number of paths.

	\section{Example}

	In our running example (Figures \ref{runningexample},
	\ref{multigraphtransformGopan} and \ref{multigraphGopan}), the analyser
	outputs the following result for the basic block $1$:

\begin{C}
RESULT FOR BASICBLOCK: -------------------
; <label>:1                                 ; preds = %10, %0
  %x.0 = phi i32 [ 0, %0 ], [ %11, %10 ]
  %y.0 = phi i32 [ 0, %0 ], [ %y.1, %10 ]
  %2 = icmp sle i32 %x.0, 50
  br i1 %2, label %3, label %5
-----
environment: dim = (2,0), count = 77
 0: x.0
 1: y.0
polyhedron of dim (2,0)
array of constraints of size 3
 0: -x.0 - y.0 + 102 >= 0
 1: y.0 >= 0
 2: x.0 - y.0 >= 0
\end{C}

First, it shows the BasicBlock we work on, and its associated abstract value:
\begin{itemize}
\item The environment of the abstract value is its dimensions. Here, $x.0$ and
$y.0$ are the dimensions of the polyhedron.
\item The array of constraints defining the polyhedron. The three constraints
here define the polyhedra seen in Figure \ref{result}.b.
\end{itemize}

 \section{Experiments}

	In this section, we evaluate our \emph{Lookahead Widening} and \emph{Path
	Focusing} implementations. We compare their execution time in some
	practical cases, and the precision of their results. Table \ref{experiments}
	gives the results of the analyser in various examples, some of them taken
	from the recent literature \cite{CGGMP05,GopanR06}.

	In all experiments, the set $P_R$ is chosen equal to $P_W \cup P_{ret} \cup
	P_{init}$,
	where $P_W$ is the set of widening points. $P_{init}$ is the set of starting
	points of the program, and $P_{ret}$ is the set of points that have no
	successors.

	\subsection{Benchmarks}

\emph{Path Focusing} appears to perform similarly or better than 
\emph{Lookahead Widening}. Indeed, it is more precise in the case of programs
containing control-flow merges inside  loops, thanks to the distinction
between all the paths of the loop. In simpler programs, it performs as well as
\emph{Lookahead Widening}

\emph{ex6.c} is a program containing non-linear arithmetic: there is an integer
multiplication inside the loop. The Apron library handles multiplication using
a linearization technique. However, multiplications is not allowed in LIA
(Linear Integer Arithmetic) or LRA (Linear Real Arithmetic). Then, Yices
SMT-solver errs with a message ``not implemented'' (which is the reason of the
$\infty$ symbol in the table), when Z3 still works correctly.

We tried our technique on example with a huge number of paths: ex8, ex8b and
ex8c (see Table \ref{npaths}). These benchmarks are constructed such that the
loop contains only a few
possible paths, but a lot of unfeasible paths. The idea is to show that our
technique does not blow up, even with a huge expanded multigraph. Results show
that in such benchmarks, our technique finds a much better invariant and is even
faster than \emph{Lookahead Widening}.

For small programs, our execution time may not be significant. Indeed, the cost
for reading the program, initialising the SMT-solver, \dots, may have a
	non-negligible cost compared to the abstract interpretation analysis itself.
	The only interest of these times is to show our algorithm is pretty fast.

\begin{table}[!h]
\begin{tabular}{|l||c|c|c|c|c|c|c|c|c|} \hline
Benchmark  & Gopan & Beyer & Boustr & ex9 & test1 & ex6 & ex8 &
ex8c & ex8b\\ \hline \hline
paths (total) & 5 & 4 & 10 & 8 & 3 & 5 & 75626 & 5.7$.10^9$ & $4.10^{14}$\\
\hline
paths (computed) & 5 & 4 & 4 & 4 & 3 & 4 & 4 & 4 & 4\\ \hline
iterations  & 6 & 5 & 5 & 4 & 3 & 4 & 4 & 4 & 4\\ \hline
\end{tabular}
\caption{Number of path in the expanded multigraph, number of path the
algorithm actually computes, and total number of iterations}
\label{npaths}
\end{table}

The last remark is about the efficiency of Yices and Z3. Yices seems to always
be slightly faster than Z3, but in some cases, Yices appeared to blow up, or to
err with a message ``not implemented'', for instance when adding non-linear
relations into the formula. Then, it was a good choice to link our analyser with
both SMT-solvers.

\begin{table}[!h]
\centering \scriptsize
\begin{tabular}{|c|c|c|l||c||c|l|} \hline

 & \multicolumn{3}{c||}{Path Focusing} & & \multicolumn{2}{c|}{Lookahead
			Widening}   \\ \cline{2-4} \cline{6-7}
Benchmark	& \multicolumn{2}{c|}{time} & result & cmp.	& time	& result	\\
\cline{2-3}	& Z3 & Yices				& & & & \\
\hline \hline

Gopan.c & 0.076s & 0.076s & \begin{tabular}{l}
-x.0 - y.0 + 102 >= 0 \\
y.0 >= 0              \\
x.0 - y.0 >= 0        
\end{tabular} & $=$ & 0.032 & \begin{tabular}{l}
-x.0 - y.0 + 102 >= 0 \\
y.0 >= 0              \\
x.0 - y.0 >= 0        
\end{tabular}  \\ \hline

Beyer.c & 0.084s & 0.076s & \begin{tabular}{l}
 -x.0  + 100 >= 0 \\
 y.0 - 50 >= 0    \\
 -x.0 + y.0 >= 0  
\end{tabular}& $=$ & 0.032 & \begin{tabular}{l}
-x.0  + 100 >= 0 \\
 y.0 - 50 >= 0 \\
-x.0 + y.0 >= 0
\end{tabular} \\ \hline

Boustr.c & 0.100s & 0.088s & \begin{tabular}{l}
 -2x.0 + d.0 + 1999 >= 0 \\
 -2x.0 + 3d.0 + 2001 >= 0 \\
 -d.0 + 1 >= 0
\end{tabular}& $\varsubsetneq$ & 0.064 & \begin{tabular}{l}
 -1996x.0 + 4991d.0 + 1998995 >= 0\\
 -2x.0 + d.0 + 1999 >= 0 \\
 -d.0 + 1 >= 0 \\
\end{tabular} \\ \hline

ex9.cpp & 0.084s & 0.082s & \begin{tabular}{l}
 r.0 = 0 \\
-i.0 + 100 >= 0 \\
i.0 >= 0
\end{tabular}& $\varsubsetneq$ & 0.052 & \begin{tabular}{l}
-i.0 + 100 >= 0\\
r.0 >= 0 \\
i.0 - r.0 >= 0 \\
24i.0 - 25r.0 + 75 >= 0
\end{tabular} \\ \hline

test1.c & 0.064s & 0.064s & \begin{tabular}{l}
2j.0 + i.0 - 21 = 0 \\
-j.0 + 10 >= 0 \\
j.0 - 6 >= 0
\end{tabular}& $=$ & 0.016 & \begin{tabular}{l}
2j.0 + i.0 - 21 = 0 \\
-j.0 + 10 >= 0 \\
j.0 - 6 >= 0
\end{tabular} \\ \hline

ex6.c & 0.104s & $\infty$ & \begin{tabular}{l}
-y.0 + 51 >= 0 \\
y.0 >= 0 \\
x.0 - 51y.0 + 2550 >= 0 \\
x.0 >= 0
\end{tabular}& $\varsubsetneq$ & 0.032 & \begin{tabular}{l}
y.0 >= 0
\end{tabular} \\ \hline

ex8.c & 0.516s & 0.408s & \begin{tabular}{l}
 -y.0 - x.0 + 1 >= 0\\
 -y.0 + x.0 + 1 >= 0\\
 y.0 - x.0 + 1 >= 0\\
 y.0 + x.0 + 1 >= 0
\end{tabular}& $\varsubsetneq$ & 0.208 & \begin{tabular}{l}
-x.0 + 1 >= 0 \\
x.0 + 1 >= 0 
\end{tabular} \\ \hline

ex8c.c & 0.656s & 0.548s & \begin{tabular}{l}
c.0 + a.0 = 0\\
b.0 + d.0 = 0\\
-b.0 - c.0 + 1 >= 0\\
-b.0 + c.0 + 1 >= 0\\
b.0 - c.0 + 1 >= 0\\
b.0 + c.0 + 1 >= 0\\
\end{tabular}& $\varsubsetneq$ & 0.916s & \begin{tabular}{l}
-b.0 + 1 >= 0\\
-b.0 + a.0 + 1 >= 0\\
-c.0 + 1 >= 0\\
-c.0 + d.0 + 1 >= 0\\
-a.0 + 1 >= 0\\
-d.0 + 1 >= 0\\
a.0 + 1 >= 0\\
c.0 - d.0 + 1 >= 0\\
c.0 + d.0 + 1 >= 0\\
b.0 - a.0 + 1 >= 0\\
b.0 + 1 >= 0\\
\end{tabular} \\ \hline

ex8b.c & 1.016s & 0.816s & \begin{tabular}{l}
c.0 + y.0 = 0\\
c.0 + a.0 = 0\\
b.0 + d.0 = 0\\
b.0 + x.0 = 0\\
-b.0 - c.0 + 1 >= 0\\
-b.0 + c.0 + 1 >= 0\\
b.0 - c.0 + 1 >= 0\\
b.0 + c.0 + 1 >= 0\\
\end{tabular}& $\varsubsetneq$ & 36.30s & \begin{tabular}{l}
-b.0 + 1 >= 0 \\
-b.0 + a.0 + 1 >= 0\\
-c.0 + 1 >= 0\\
-c.0 + d.0 + 1 >= 0\\
-a.0 + 1 >= 0\\
-y.0 - x.0 + 1 >= 0\\
-y.0 + x.0 + 1 >= 0\\
-d.0 + 1 >= 0\\
x.0 + 1 >= 0\\
y.0 - x.0 + 1 >= 0\\
y.0 + 1 >= 0\\
a.0 + 1 >= 0\\
c.0 - d.0 + 1 >= 0\\
c.0 + d.0 + 1 >= 0\\
b.0 - a.0 + 1 >= 0\\
b.0 + 1 >= 0\\
\end{tabular}\\ \hline


\end{tabular}
\caption{Results of \emph{Path Focusing} and \emph{Lookahead Widening}
techniques applied to various benchmarks. The invariant we give is the one at
the head of the loop.}
\label{experiments}
\end{table}


	\subsection{Analysis of real code}

	In this section, we show that \emph{Path Focusing} technique performs better
	that \emph{Lookahead widening} on some code taken from real open-source
	programs.

	\subsubsection{Analysis of cBench programs}
	Collective Benchmark (cBench) \cite{cbench} 
	is a collection of open-source sequential
	programs assembled by the community to enable realistic
	benchmarking and research on program.

	We compare \emph{Lookahead Widening} and \emph{Path Focusing} techniques on
	these benchmarks, and we respectively count the number of BasicBlocks where
	the invariant is more precise with the first technique, or with the second
	one, or if it the invariant is the same (see Table \ref{cbench}).

	These benchmarks often contain non-linear arithmetic, especially
	multiplications. This is not a problem to the Apron library since it uses
	linearization to handle them, but this sometimes implies an execution time
	blowup for the SMT-solver:
\begin{itemize}
\item \emph{Yices} does not work at all when the formula contains non-linear
arithmetic, so we could not use it. Indeed, Linear Real Arithmetic or Linear
Integer Arithmetic theories do not treat multiplications.
\item \emph{Z3} implements some linearization techniques 
in order to deal with non-linear
arithmetic, even if the used theory is LRA or LIA. In lots of cases, it is
sufficient for deciding the satisfiability of our formulae, but it seems
sometimes to have a huge execution time blowup. 
When running our benchmarks, we fixed a time limit (5 minutes) for the analysis,
and ignore in our results the functions that make the SMT-solver blow.
\end{itemize}
	This drawback could be solved in the future, by linearizing parts of the
	SMT-formula that make the computation too costly, or make it fail (in some
	cases, the SMT-solver is unable to decide the satisfiability of the formula,
	and answers ``unknown'').

	\emph{Path Focusing} technique finds more precise invariants in some cases,
	whereas \emph{Lookahead Widening} performs better in other cases.
	This is partly due to the widening operator: even if the analysis is more
	subtle, the result at the end may be worse.

\begin{table}[!h]
\centering
\begin{tabular}{|c||c|c|c|c|} \hline 
Benchmark & Path Focusing & Lookahead Widening & Same invariant & Total \\
\hline \hline
%automotive\_bitcount	& 1 & 0 & 39 & 40 \\ \hline
%automotive\_qsort1		& 7 & 0 & 9 & 16 \\ \hline
%automotive\_susan\_c	& 0 & 0 & 3 & 3 \\ \hline
%automotive\_susan\_e	& 0 & 0 & 3 & 3 \\ \hline
%automotive\_susan\_s	& 0 & 0 & 3 & 3 \\ \hline
%bzip2d					& 8 & 0 & 22 & 30 \\ \hline
%bzip2e					& 8 & 0 & 22 & 30 \\ \hline
%consumer\_jpeg\_c		& 35 & 0 & 693 & 728 \\ \hline
%consumer\_jpeg\_d		& 30 & 0 & 662 & 692 \\ \hline
%consumer\_lame			& 31 & 12 & 372  & 415 \\ \hline
%consumer\_mad			& 9 & 8 & 579 & 596 \\ \hline
%consumer\_tiff2bw		& 18 & 1 & 576 & 595 \\ \hline
%consumer\_tiff2rgba		& 19 & 1 & 574 & 594\\ \hline
%consumer\_tiffdither	& 17 & 1 & 574 & 592 \\ \hline
%consumer\_tiffmedian	& 21 & 2 & 620 & 643 \\ \hline
%network\_patricia		& 2 & 0 & 21 & 23 \\ \hline
%office\_rsynth			& 8 & 0 & 158 & 166\\ \hline
%office\_stringsearch1	& 5 & 1 & 44 & 50\\ \hline
%security\_blowfish\_d	& 4 & 0 & 23 & 27\\ \hline
%security\_blowfish\_e	& 4 & 0 & 23 & 27\\ \hline
%security\_rijndael\_d	& 2 & 0 & 30 & 32\\ \hline
%security\_rijndael\_e	& 2 & 0 & 30 & 32\\ \hline
%security\_sha			& 1 & 0 & 26 & 27\\ \hline
%telecom\_adpcm\_c		& 0 & 0 & 10 & 10\\ \hline
%telecom\_adpcm\_d		& 0 & 0 & 10 & 10\\ \hline
%telecom\_CRC32			& 0 & 0 & 13 & 13\\ \hline
%telecom\_gsm			& 4 & 0 & 89 & 93\\ \hline
%%%%%%%%%%%%
automotive\_bitcount & 1 & 0 & 39 & 40 \\ \hline
automotive\_qsort1 & 9 & 0 & 13 & 22 \\ \hline
automotive\_susan\_c & 0 & 2 & 59 & 61 \\ \hline
automotive\_susan\_e & 0 & 2 & 59 & 61 \\ \hline
automotive\_susan\_s & 0 & 2 & 59 & 61 \\ \hline
bzip2d & 70 & 3 & 81 & 154 \\ \hline
bzip2e & 70 & 3 & 81 & 154 \\ \hline
consumer\_jpeg\_c & 22 & 8 & 711 & 741 \\ \hline
consumer\_jpeg\_d & 13 & 8 & 667 & 688 \\ \hline
consumer\_lame & 13 & 15 & 366 & 394 \\ \hline
consumer\_mad & 12 & 11 & 609 & 632 \\ \hline
consumer\_tiff2bw & 19 & 3 & 593 & 615 \\ \hline
consumer\_tiff2rgba & 21 & 6 & 661 & 688 \\ \hline
consumer\_tiffdither & 21 & 3 & 662 & 686 \\ \hline
consumer\_tiffmedian & 25 & 5 & 707 & 737 \\ \hline
network\_dijkstra & 0 & 0 & 19 & 19 \\ \hline
network\_patricia & 2 & 0 & 21 & 23 \\ \hline
office\_rsynth & 6 & 0 & 158 & 164 \\ \hline
office\_stringsearch1 & 5 & 1 & 44 & 50 \\ \hline
security\_blowfish\_d & 4 & 0 & 23 & 27 \\ \hline
security\_blowfish\_e & 4 & 0 & 23 & 27 \\ \hline
security\_rijndael\_d & 1 & 0 & 31 & 32 \\ \hline
security\_rijndael\_e & 1 & 0 & 31 & 32 \\ \hline
security\_sha & 1 & 0 & 26 & 27 \\ \hline
telecom\_CRC32 & 0 & 0 & 13 & 13 \\ \hline
telecom\_adpcm\_c & 0 & 0 & 10 & 10 \\ \hline
telecom\_adpcm\_d & 0 & 0 & 10 & 10 \\ \hline
telecom\_gsm & 5 & 0 & 153 & 158 \\ \hline
\end{tabular}
\caption{Number of basicblocks where the computed invariant is more precise by
\emph{Path Focusing}, \emph{Lookahead Widening}, or the same with both
techniques.}
\label{cbench}
\end{table}

	\subsubsection{Analysis of Open Source projects}

We compare \emph{Lookahead Widening} and \emph{Path Focusing} on various
GNU projects ( see Table \ref{opensource}), so that we can see their precision
on really used code.

The results we obtain are very promising. Most of the cases, our technique
performs as well as \emph{Lookahead Widening}, and discovers regularly more
precise invariants.

However, \emph{Lookahead Widening} seems to have better results in some cases.
We already have some ideas for explaining this lack of precision in our
technique:

\begin{itemize}
\item We use the domain of convex polyhedra as the abstract domain. Since this
domain requires a widening operator, a more subtle analysis technique may
sometimes discover invariants that are less precise than a more simplified
technique.
\item Our technique performs well in the case of self loops in the multigraph,
thanks to the widening/narrowing phases (or acceleration). Yet, in the case of
paths that do not constitute a self loop in the multigraph, one performs a
widening operation, but no narrowing iteration. Apparently, lots of the cases
where \emph{Lookahead Widening} performs better than \emph{Path Focusing} are
due to this drawback. An example of such loss of precision is depicted in
appendix \ref{lostprecision}.
An idea that could solve this problem is to try to combine
the two methods (see \ref{combining}).
\end{itemize}

Although these project are not safety-critical and do not necessarily need
static analysis, they give a good idea of the quality of our technique and the
scalability of our implementation.

\begin{table}
\centering
\begin{tabular}{|c||c|c|c|c|} \hline 
Benchmark & Path Focusing & Lookahead Widening & Same invariant & Total \\
\hline \hline
Bc			& 0 & 0 & 177 & 177 \\ \hline
Gawk		& 4 & 3 & 284 & 291 \\ \hline
Gnuchess	& 22 & 33 & 1506 & 1561 \\ \hline
Gnugo		& 105 & 35 & 1303 & 1443 \\ \hline
Grep		& 4 & 3 & 323 & 330 \\ \hline
Gzip		& 9 & 3 & 189 & 201 \\ \hline
Make		&  7 & 11 & 457 & 475 \\ \hline
Tar			& 16 & 5 & 555 & 576 \\ \hline
Wget		& 8 & 12 & 715 & 735 \\ \hline
\end{tabular}
\caption{Result of the analysis of various open-source projects.}
\label{opensource}
\end{table}

\chapter{Future Work}
\label{future}
\emph{Path Focusing} technique allows to work on control flow graphs with a huge
number of paths, since they are computed only when needed. With this in mind,
one could think of several improvements using path focusing, by encoding into
the control flow graph new informations as paths, such as arithmetic overflows,
alias analysis, \dots
In this part, we explain how to encode such kind of informations into implicit
paths of the CFG.

	\section{Arithmetic Overflows}

Some operations such as additions, subtractions\dots may overflow if their
result is not in the type's definition interval. For instance, an
\emph{int} variable can only take values in $[-2^{31}, 2^{31} -1]$. Then, there
are two kind of overflows. Suppose $N=2^{31}$:
\begin{itemize}
\item The result $r$ of the operation may be greater than $N-1$. In this case,
the result we obtain is actually $r-2N$.
\item $r$ may be lesser than $-N$. Then, the result is $r+2N$.
\end{itemize}

The idea would be to distinguish the correct behaviour and the two kind of
overflow in the control flow graph, each behaviour corresponding to a specific
path (see Figure \ref{overflow}).

\begin{figure}[!h]
\centering
\begin{tikzpicture}[->,>=stealth',auto,node distance=3cm,
                    semithick,font=\footnotesize]
	\node[state] (n0) {};
	\node[state] (n1) [below of=n0] {};

	\path [transition] 
		(n0) edge [out=-140,in=140]  node [xshift=-0.2mm] 
		{$\begin{array}{l} x+y < -N\ /\\ r=x+y+2N\end{array}$} (n1)
		(n0) edge [in=170,out=190,distance=2cm]  node [left]
		{$\begin{array}{l} x+y > N-1\ / \\ r=x+y-2N\end{array}$} (n1)
		(n0) edge [in=10,out=-10,distance=2.5cm]  node [right] 
		{$\begin{array}{l} -N \leq x+y \leq N-1\ /\\ r=x+y\end{array}$} (n1)
		;
\end{tikzpicture}
\caption{How to treat overflows of the addition $x+y$}
\label{overflow}
\end{figure}

This results in a huge blowup in the number of paths, but hopefully a lot of
them will never be possible, so they will never be computed by our algorithm.

	\section{Alias analysis}

One could use the same idea as for overflows, in order to treat aliases.
Assume a pointer $p$ that possibly points to variables $x,y,z$ or $t$. For each
operation involving $*p$, one distinguishes these different cases by
creating a specific path for each of them. 
If the pointers are manipulated in a tricky way, one considers they may
point to each variable of the program. Again, there is an exponential blowup in
the number of paths, but these are treated implicitly.

\begin{figure}[!h]
\centering
\begin{tikzpicture}[->,>=stealth',auto,node distance=3cm,
                    semithick,font=\footnotesize]
	\node[state] (n0) {};
	\node[state] (n1) [below of=n0] {};

	\path [transition] 
		(n0) edge [in=170,out=190,distance=2.5cm]  node [left] 
		{$\begin{array}{l}p=\&x/ \\ x++\end{array}$} (n1);
	\path [transition] 
		(n0) edge  [in=120, out=-120] node [left,xshift=0.2cm] 
		{$\begin{array}{l}p=\&y/ \\ y++\end{array}$} (n1);
	\path [transition] 
		(n0) edge [in=60,out=-60]  node  [right,xshift=-0.2cm]
		{$\begin{array}{l}p=\&z/ \\ z++\end{array}$} (n1);
	\path [transition] 
		(n0) edge [in=10,out=-10,distance=2.5cm]  node [right] 
		{$\begin{array}{l}p=\&t/ \\ t++\end{array}$} (n1);
\end{tikzpicture}
\caption{How to treat pointers: $(*p)++$}
\label{pointers}
\end{figure}

	\section{Combining Lookahead Widening and Path Focusing}
	\label{combining}
	Path Focusing technique works on the expanded multigraph.
	Its limitation is that it does narrowing
	sequences during the iterations only for self-loops of this multigraph.
	
	Lookahead Widening works on the classical control flow graph, and stabilises
	temporarily the fixpoint analysis on a part of this graph, forgetting paths
	that are not feasible at the first iteration.

	One could try to combine these two techniques, and apply Lookahead Widening
	on the expanded multigraph, where the different paths are maintained
	implicit thanks to Path Focusing technique. The advantage of this approach
	compared to the classical Path Focusing is that narrowing iterations could
	be computed on loops that are not self-loops.

\chapter{Conclusion}
  
	Validation of software has become an essential domain in industry,
	especially those dealing with embedded systems, where a bug in the program
	can endanger the safety of people, or induce huge costs to fix. These
	domains constitute a privileged application field for formal verification
	techniques.
	Abstract Interpretation is a common used technique to do static analysis of
	programs. It is aimed at computing iteratively an over-approximation of the set of
	possible states of the program, and allows to prove properties such as
	``In this program, $x$ is always between 1 and 10'', ``The program never
	divides by zero'', etc. The objective is to obtain a result as precise as
	possible, by limiting the loss of precision during the analysis, induced for
	instance by the widening operator, or control-flow merges.

	In this report, we proposed a new approach to guide the iterations of the
	analyser, in order to distinguish the different paths of the program
	and to treat them
	independently. The loss of precision due to widening and control-flow merges
	is then reduced. This technique allows us, for instance, to do narrowing
	steps right after widening, or to use acceleration techniques when a path
	actually is a simple loop.

	Since distinguishing all the paths leads to an exponential blowup in time
	and memory, we do compute a path only when needed, otherwise the path is
	kept implicit. In this way, memory consumption is preserved, and the
	computation time is reduced, but still potentially exponential.
	In order to find which path we should compute, we use SMT-solving to find
	paths that makes the abstract interpretation analysis progress.

	We implemented this technique into a small analyser dealing with C and C++
	programs, and run it on several
	benchmarks.
	It appears that in lots of cases, 
	the precision of the result is improved 
	compared to the classical abstract interpretation technique.
	We compared it with \emph{Lookahead Widening}, and our technique seems to
	perform better in the case of loops containing control-flow merges. 

	Our analyser is able to deal with small- and middle-sized test-cases, as
	well as real-life programs. It looses
	precision in the case of programs with pointers or several functions.
	It has been tested with program having loops containing several hundreds
	lines of code, and gave results after a time in the order of the second.
	It could be improved in many ways, in order to support
	for instance interprocedural analysis. A memory model could be added to
	handle programs with pointers and \emph{load/store} instructions.
	One could also try to compute disjunctive invariants using the technique
	described in this report.
	Since our technique combines well with acceleration techniques, another
	direction is to implement this last technique to improve our results
	obtained with classical widening/narrowing.
	

	\emph{Path Focusing} technique performs better thanks to the distinction
	between
	paths. Then, encoding some properties in the control flow graph, such as
	arithmetic overflows or aliases, is one direction to explore. One could also
	try to combine \emph{Path Focusing} with other techniques, such as
	\emph{Lookahead Widening}.


\bibliographystyle{alpha}
  \bibliography{report}

\addcontentsline{toc}{chapter}{Bibliography}
  \appendix
\appendixpage
\renewcommand{\thesection}{\Alph{section}}
\section{Generated $\rho$ formula}
\label{rhoformula}
\begin{figure}[!h]
\begin{C}
(and (= bd_0 false)
        (= t_0_1 bs_0)
        (or (not bd_0) true)
        (= b_5 t_1_5)
        (= x_%6_ (+ x_y.0_ -1))
        (= t_5_7 b_5)
        (or (not b_5) true)
        (= b_3 t_1_3)
        (= x_%4_ (+ x_y.0_ 1))
        (= t_3_7 b_3)
        (or (not b_3) true)
        (= b_7
           (or t_5_7 t_3_7))
        (= t_7_9 (and b_7 (< x_y.1_ 0)))
        (= t_7_10
           (and b_7 (not (< x_y.1_ 0))))
        (or (not b_7)
            (= x_y.1_ (ite t_3_7 x_%4_ x_%6_)))
        (= b_10 t_7_10)
        (= x_%11_ (+ x_x.0_ 1))
        (= t_10_1 b_10)
        (or (not b_10) true)
        (= bd_1
           (or t_10_1 t_0_1))
        (= t_1_3 (and bs_1 (<= x_x.0_ 50)))
        (= t_1_5
           (and bs_1 (not (<= x_x.0_ 50))))
        (or (not bd_1)
            (and (= x'_x.0_ (ite t_0_1 0 x_%11_))
                 (= x'_y.0_ (ite t_0_1 0 x_y.1_))))
        (= b_9 t_7_9)
        (= t_9_12 b_9)
        (or (not b_9) true)
        (= bd_12 t_9_12)
        (or (not bd_12) true))
\end{C}
\caption{Expression of $\rho$ associated to the program in Figures
\ref{runningexample}, \ref{multigraphtransformGopan} and
\ref{multigraphGopan}, in the SMT-lib format.}
\end{figure}
\FloatBarrier

\newpage
\section{Example of loss of precision in Path Focusing}
\label{lostprecision}
The following graph is a simplified example taken from one of our benchmarks,
where \emph{Path Focusing} technique obtains bad results.
\begin{figure}[!h]
\centering
\begin{tikzpicture}[->,>=stealth',auto,node distance=2.5cm,
                    semithick,font=\footnotesize]

	\node[rstate] (n0) {$p_0$};
	\node[rstate] (n1) [below of=n0] {\begin{tabular}{l}
	$p_1$: \\
	$i \gets \Phi(0,i')$
	\end{tabular}};
	\node[rstate] (n2) [below left of=n1] {$p_2$};
	\node[rstate] (n3) [below right of=n2] {$p_3$};

  \path [transition] 
		(n0) edge              node {} (n1);
  \path [transition] 
        (n1) edge			   node [left] {$i \leq 50$} (n2);
  \path [transition] 
        (n2) edge	[loop left, distance=2cm]	   node  {} (n2);
  \path [transition] 
        (n2) edge			   node  {} (n3);
  \path [transition] 
        (n3) edge			   node [right] {$i' \gets i+1$} (n1);
\end{tikzpicture}
\end{figure}

$p_1$ and $p_2$ are both loop headers. We have $P_R = \{p_1, p_2\}$.

\begin{itemize}
\item We start with $p_1$ : $i=0$. The SMT-solver finds the path $p_1 \rightarrow p_2$.
\item At point $p_2$ : $i=0$. Then, we focus on the path $p_2 \rightarrow p_3 \rightarrow p_1$.
The obtained invariant in $p_1$ becomes $i \in [0,1]$. 
Since this is a loop header, widening is applied: $i \geq 0$.
\item The new focus path is $p_1 \rightarrow p_2$. The image of the polyhedron $i
\geq 0$ by this transition is $0 \leq i \leq 50$. Again, $p_2$  is a loop
header, and widening gives $i \geq 0$.
\end{itemize}
In this example, we do not have narrowing iterations since we never focus on self
loops.


\end{document}
